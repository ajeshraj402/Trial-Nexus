{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83885d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: Dataset(id='clinicaltrials/2021/trec-ct-2021', provides=['docs', 'queries', 'qrels'])\n",
      "Num topics: 75\n",
      "Num qrels rows: 35832\n",
      "Topics with at least 1 judged relevant doc: 75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\nPatient is a 45-year-old man with a history ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\\n48 M with a h/o HTN hyperlipidemia, bicuspid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\\nA 32 yo woman who presents following a sever...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  topic_id                                               text\n",
       "0        1  \\nPatient is a 45-year-old man with a history ...\n",
       "1        2  \\n48 M with a h/o HTN hyperlipidemia, bicuspid...\n",
       "2        3  \\nA 32 yo woman who presents following a sever..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00002569</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00002620</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00002806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00002814</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00003022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  topic_id       doc_id  relevance\n",
       "0        1  NCT00002569          1\n",
       "1        1  NCT00002620          1\n",
       "2        1  NCT00002806          0\n",
       "3        1  NCT00002814          2\n",
       "4        1  NCT00003022          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ir_datasets\n",
    "import pandas as pd\n",
    "\n",
    "# Load TREC Clinical Trials 2021 benchmark set (topics + qrels)\n",
    "ds = ir_datasets.load(\"clinicaltrials/2021/trec-ct-2021\")\n",
    "\n",
    "# --- Load queries (patient topics) ---\n",
    "queries = []\n",
    "for q in ds.queries_iter():\n",
    "    # q: (query_id, text)\n",
    "    queries.append({\"topic_id\": q.query_id, \"text\": q.text})\n",
    "queries_df = pd.DataFrame(queries)\n",
    "\n",
    "# --- Load qrels (relevance judgments) ---\n",
    "qrels = []\n",
    "for qr in ds.qrels_iter():\n",
    "    # qr: (query_id, doc_id, relevance, iteration)\n",
    "    qrels.append({\"topic_id\": qr.query_id, \"doc_id\": qr.doc_id, \"relevance\": int(qr.relevance)})\n",
    "qrels_df = pd.DataFrame(qrels)\n",
    "\n",
    "print(\"Loaded dataset:\", ds)\n",
    "print(\"Num topics:\", len(queries_df))\n",
    "print(\"Num qrels rows:\", len(qrels_df))\n",
    "print(\"Topics with at least 1 judged relevant doc:\",\n",
    "      qrels_df[qrels_df[\"relevance\"] > 0][\"topic_id\"].nunique())\n",
    "\n",
    "display(queries_df.head(3))\n",
    "display(qrels_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25138acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading trial documents: 375580it [00:02, 147552.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial documents loaded\n",
      "Total number of trials: 375580\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT00000102</td>\n",
       "      <td>Congenital Adrenal Hyperplasia: Calcium Channe...</td>\n",
       "      <td>\\n    \\n      This study will test the ability...</td>\n",
       "      <td>\\n    \\n      This protocol is designed to ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT00000104</td>\n",
       "      <td>Does Lead Burden Alter Neuropsychological Deve...</td>\n",
       "      <td>\\n    \\n      Inner city children are at an in...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCT00000105</td>\n",
       "      <td>Vaccination With Tetanus and KLH to Assess Imm...</td>\n",
       "      <td>\\n    \\n      The purpose of this study is to ...</td>\n",
       "      <td>\\n    \\n      Patients will receive each vacci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        doc_id                                              title  \\\n",
       "0  NCT00000102  Congenital Adrenal Hyperplasia: Calcium Channe...   \n",
       "1  NCT00000104  Does Lead Burden Alter Neuropsychological Deve...   \n",
       "2  NCT00000105  Vaccination With Tetanus and KLH to Assess Imm...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  \\n    \\n      This study will test the ability...   \n",
       "1  \\n    \\n      Inner city children are at an in...   \n",
       "2  \\n    \\n      The purpose of this study is to ...   \n",
       "\n",
       "                                         description  \n",
       "0  \\n    \\n      This protocol is designed to ass...  \n",
       "1                                                     \n",
       "2  \\n    \\n      Patients will receive each vacci...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Load the full ClinicalTrials corpus used in TREC CT 2021\n",
    "docs = []\n",
    "for doc in tqdm(ds.docs_iter(), desc=\"Loading trial documents\"):\n",
    "    # doc: (doc_id, title, summary, detailed_description, ...)\n",
    "    docs.append({\n",
    "        \"doc_id\": doc.doc_id,\n",
    "        \"title\": doc.title,\n",
    "        \"summary\": doc.summary,\n",
    "        \"description\": doc.detailed_description\n",
    "    })\n",
    "\n",
    "docs_df = pd.DataFrame(docs)\n",
    "\n",
    "print(\"Trial documents loaded\")\n",
    "print(\"Total number of trials:\", len(docs_df))\n",
    "\n",
    "display(docs_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21644285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing corpus: 100%|██████████| 375580/375580 [00:36<00:00, 10224.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 index ready\n",
      "Num docs indexed: 375580\n",
      "Example tokens: ['congenital', 'adrenal', 'hyperplasia', 'calcium', 'channels', 'as', 'therapeutic', 'targets', 'this', 'study', 'will', 'test', 'the', 'ability', 'of', 'extended', 'release', 'nifedipine', 'procardia', 'xl', 'a', 'blood', 'pressure', 'medication', 'to', 'permit', 'a', 'decrease', 'in', 'the']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from rank_bm25 import BM25Okapi\n",
    "from tqdm import tqdm\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def tokenize(s: str):\n",
    "    # simple tokenizer: words + numbers\n",
    "    return re.findall(r\"[a-z0-9]+\", normalize_text(s))\n",
    "\n",
    "# Build a compact text per doc (keeps memory reasonable)\n",
    "doc_ids = docs_df[\"doc_id\"].tolist()\n",
    "doc_texts = (docs_df[\"title\"].fillna(\"\") + \" \" +\n",
    "             docs_df[\"summary\"].fillna(\"\") + \" \" +\n",
    "             docs_df[\"description\"].fillna(\"\")).tolist()\n",
    "\n",
    "# Tokenize corpus for BM25\n",
    "tokenized_corpus = [tokenize(t) for t in tqdm(doc_texts, desc=\"Tokenizing corpus\")]\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "print(\"BM25 index ready\")\n",
    "print(\"Num docs indexed:\", len(doc_ids))\n",
    "print(\"Example tokens:\", tokenized_corpus[0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4efb0c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving top 100: 100%|██████████| 75/75 [16:10<00:00, 12.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run generated\n",
      "Rows in run: 7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT03528642</td>\n",
       "      <td>1</td>\n",
       "      <td>293.930154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00003176</td>\n",
       "      <td>2</td>\n",
       "      <td>290.582836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT02942264</td>\n",
       "      <td>3</td>\n",
       "      <td>288.751092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT01466686</td>\n",
       "      <td>4</td>\n",
       "      <td>287.161880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT03633552</td>\n",
       "      <td>5</td>\n",
       "      <td>286.098323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00841555</td>\n",
       "      <td>6</td>\n",
       "      <td>286.027940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00968240</td>\n",
       "      <td>7</td>\n",
       "      <td>279.294295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00089427</td>\n",
       "      <td>8</td>\n",
       "      <td>277.892832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00734682</td>\n",
       "      <td>9</td>\n",
       "      <td>276.883413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00003537</td>\n",
       "      <td>10</td>\n",
       "      <td>276.226250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  topic_id       doc_id  rank       score\n",
       "0        1  NCT03528642     1  293.930154\n",
       "1        1  NCT00003176     2  290.582836\n",
       "2        1  NCT02942264     3  288.751092\n",
       "3        1  NCT01466686     4  287.161880\n",
       "4        1  NCT03633552     5  286.098323\n",
       "5        1  NCT00841555     6  286.027940\n",
       "6        1  NCT00968240     7  279.294295\n",
       "7        1  NCT00089427     8  277.892832\n",
       "8        1  NCT00734682     9  276.883413\n",
       "9        1  NCT00003537    10  276.226250"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "K = 100\n",
    "\n",
    "runs = []  # list of dicts: topic_id, doc_id, rank, score\n",
    "\n",
    "for row in tqdm(queries_df.itertuples(index=False), total=len(queries_df), desc=f\"Retrieving top {K}\"):\n",
    "    topic_id = str(row.topic_id)\n",
    "    query_text = row.text\n",
    "\n",
    "    q_tokens = tokenize(query_text)\n",
    "    scores = bm25.get_scores(q_tokens)  # numpy array aligned with doc_ids\n",
    "\n",
    "    top_idx = np.argpartition(scores, -K)[-K:]          # unsorted top-K indices\n",
    "    top_idx = top_idx[np.argsort(scores[top_idx])[::-1]]  # sort descending\n",
    "\n",
    "    for rank, idx in enumerate(top_idx, start=1):\n",
    "        runs.append({\n",
    "            \"topic_id\": topic_id,\n",
    "            \"doc_id\": doc_ids[idx],\n",
    "            \"rank\": rank,\n",
    "            \"score\": float(scores[idx])\n",
    "        })\n",
    "\n",
    "run_df = pd.DataFrame(runs)\n",
    "\n",
    "print(\"Run generated\")\n",
    "print(\"Rows in run:\", len(run_df))\n",
    "display(run_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3932414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved run file to:\n",
      "C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\bm25_python_trec2021_top100.run\n",
      "\n",
      "Evaluation (BM25 python baseline):\n",
      "K=10   Precision@10:  0.3000   Recall@10:  0.0279\n",
      "K=100  Precision@100: 0.1485   Recall@100: 0.1040\n",
      "\n",
      "Saved metrics to:\n",
      "C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\bm25_python_trec2021_metrics.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precision@10</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recall@10</td>\n",
       "      <td>0.027917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision@100</td>\n",
       "      <td>0.148533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall@100</td>\n",
       "      <td>0.104029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          metric     value\n",
       "0   Precision@10  0.300000\n",
       "1      Recall@10  0.027917\n",
       "2  Precision@100  0.148533\n",
       "3     Recall@100  0.104029"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# ---------- project-aligned paths ----------\n",
    "BASE_DIR = Path(r\"C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\")\n",
    "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "run_path = BASE_DIR / \"bm25_python_trec2021_top100.run\"\n",
    "metrics_path = BASE_DIR / \"bm25_python_trec2021_metrics.csv\"\n",
    "\n",
    "# ---------- save TREC run file ----------\n",
    "runname = \"bm25_python\"\n",
    "\n",
    "with open(run_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for r in run_df.itertuples(index=False):\n",
    "        f.write(f\"{r.topic_id} Q0 {r.doc_id} {r.rank} {r.score:.6f} {runname}\\n\")\n",
    "\n",
    "print(\"Saved run file to:\")\n",
    "print(run_path)\n",
    "\n",
    "# ---------- evaluation (P@K, R@K) ----------\n",
    "def precision_recall_at_k(run_df: pd.DataFrame, qrels_df: pd.DataFrame, k: int):\n",
    "    rel = (\n",
    "        qrels_df[qrels_df[\"relevance\"] > 0]\n",
    "        .groupby(\"topic_id\")[\"doc_id\"]\n",
    "        .apply(set)\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    topk = (\n",
    "        run_df.sort_values([\"topic_id\", \"rank\"])\n",
    "        .groupby(\"topic_id\")\n",
    "        .head(k)\n",
    "        .groupby(\"topic_id\")[\"doc_id\"]\n",
    "        .apply(list)\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    topics = sorted(set(rel.keys()) & set(topk.keys()))\n",
    "    precisions, recalls = [], []\n",
    "\n",
    "    for t in topics:\n",
    "        retrieved = topk.get(t, [])\n",
    "        relevant = rel.get(t, set())\n",
    "\n",
    "        hits = sum(1 for d in retrieved if d in relevant)\n",
    "        precisions.append(hits / k)\n",
    "        recalls.append(hits / len(relevant))\n",
    "\n",
    "    return sum(precisions) / len(precisions), sum(recalls) / len(recalls)\n",
    "\n",
    "p10, r10 = precision_recall_at_k(run_df, qrels_df, k=10)\n",
    "p100, r100 = precision_recall_at_k(run_df, qrels_df, k=100)\n",
    "\n",
    "metrics_df = pd.DataFrame([\n",
    "    {\"metric\": \"Precision@10\", \"value\": p10},\n",
    "    {\"metric\": \"Recall@10\", \"value\": r10},\n",
    "    {\"metric\": \"Precision@100\", \"value\": p100},\n",
    "    {\"metric\": \"Recall@100\", \"value\": r100},\n",
    "])\n",
    "\n",
    "metrics_df.to_csv(metrics_path, index=False)\n",
    "\n",
    "print(\"\\nEvaluation (BM25 python baseline):\")\n",
    "print(f\"K=10   Precision@10:  {p10:.4f}   Recall@10:  {r10:.4f}\")\n",
    "print(f\"K=100  Precision@100: {p100:.4f}   Recall@100: {r100:.4f}\")\n",
    "\n",
    "print(\"\\nSaved metrics to:\")\n",
    "print(metrics_path)\n",
    "\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82eba02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reloading trial docs with eligibility: 375580it [00:02, 140614.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Rebuilt docs_df with eligibility field\n",
      "Total docs: 375580\n",
      "Eligibility non-empty: 374648\n",
      "\n",
      "==============================\n",
      "DOC: NCT03528642\n",
      "Eligibility text length: 7218\n",
      "Inclusion found: 58\n",
      "Exclusion found: 30\n",
      "Inclusion sample: ['Patients must have histopathologic or molecular confirmation of either IDH-mutant DA', 'or IDH-mutant AA. Acceptable IDH mutations for study eligibility include any IDH1', 'mutation at codon 132 or any IDH2 mutation at codon 172.']\n",
      "Exclusion sample: ['Patients must not have received prior chemotherapy to treat the glioma.', 'Patients who are receiving any other investigational agents.', 'History of allergic reactions attributed to compounds of similar chemical or biologic']\n",
      "\n",
      "==============================\n",
      "DOC: NCT00003176\n",
      "Eligibility text length: 3027\n",
      "Inclusion found: 0\n",
      "Exclusion found: 0\n",
      "Inclusion sample: []\n",
      "Exclusion sample: []\n",
      "\n",
      "==============================\n",
      "DOC: NCT02942264\n",
      "Eligibility text length: 9312\n",
      "Inclusion found: 99\n",
      "Exclusion found: 6\n",
      "Inclusion sample: ['of prior disease relapses', 'Patients must have pathologic diagnosis of anaplastic astrocytoma defined as WHO grade', 'III or glioblastoma/gliosarcoma, WHO grade IV, which are confirmed by NCI Laboratory']\n",
      "Exclusion sample: ['Patients who are receiving any other investigational agents. However, prior enrollment', 'on a study using investigational agents is acceptable', 'Patients with prior bevacizumab use for tumor treatment. Patients who received']\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Rebuild docs_df including eligibility field (this is where criteria live)\n",
    "docs = []\n",
    "for doc in tqdm(ds.docs_iter(), desc=\"Reloading trial docs with eligibility\"):\n",
    "    docs.append({\n",
    "        \"doc_id\": doc.doc_id,\n",
    "        \"title\": doc.title,\n",
    "        \"summary\": doc.summary,\n",
    "        \"description\": doc.detailed_description,\n",
    "        \"eligibility\": doc.eligibility\n",
    "    })\n",
    "\n",
    "docs_df = pd.DataFrame(docs)\n",
    "\n",
    "print(\"✅ Rebuilt docs_df with eligibility field\")\n",
    "print(\"Total docs:\", len(docs_df))\n",
    "print(\"Eligibility non-empty:\", (docs_df[\"eligibility\"].fillna(\"\").str.strip() != \"\").sum())\n",
    "\n",
    "# Rebuild fast lookup to include eligibility\n",
    "docs_lookup = (\n",
    "    docs_df.set_index(\"doc_id\")[[\"title\", \"summary\", \"description\", \"eligibility\"]]\n",
    "    .fillna(\"\")\n",
    "    .to_dict(orient=\"index\")\n",
    ")\n",
    "\n",
    "def get_trial_text(doc_id: str) -> str:\n",
    "    d = docs_lookup.get(doc_id, {\"title\": \"\", \"summary\": \"\", \"description\": \"\", \"eligibility\": \"\"})\n",
    "    return (d[\"title\"] + \"\\n\" + d[\"summary\"] + \"\\n\" + d[\"description\"] + \"\\n\" + d[\"eligibility\"]).strip()\n",
    "\n",
    "# Re-run sanity check on the same 3 docs from topic 1\n",
    "sample_doc_ids = run_df[run_df[\"topic_id\"] == \"1\"].sort_values(\"rank\").head(3)[\"doc_id\"].tolist()\n",
    "\n",
    "for did in sample_doc_ids:\n",
    "    t = get_trial_text(did)\n",
    "    elig = extract_eligibility(t)\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"DOC:\", did)\n",
    "    print(\"Eligibility text length:\", len(docs_lookup[did][\"eligibility\"]))\n",
    "    print(\"Inclusion found:\", len(elig[\"inclusion\"]))\n",
    "    print(\"Exclusion found:\", len(elig[\"exclusion\"]))\n",
    "    print(\"Inclusion sample:\", elig[\"inclusion\"][:3])\n",
    "    print(\"Exclusion sample:\", elig[\"exclusion\"][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35983c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient preview: Patient is a 45-year-old man with a history of anaplastic astrocytoma of the spine complicated by severe lower extremity weakness and urinary retention s/p Foley catheter, high-dose steroids, hypertension, and chronic...\n",
      "Trial: NCT03528642 | inclusion: 58 | exclusion: 30\n",
      "\n",
      "--- Sending to Ollama ---\n",
      "\n",
      "--- Raw model output (first 800 chars) ---\n",
      "Here is the eligibility assessment:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"trial_id\": \"NCT03528642\",\n",
      "  \"overall_assessment\": \"likely_eligible\",\n",
      "  \"inclusion\": [\n",
      "    {\n",
      "      \"criterion\": \"histopathologic or molecular confirmation of either IDH-mutant DA or IDH-mutant AA\",\n",
      "      \"label\": \"met\",\n",
      "      \"evidence\": \"The tumor is located in the T-L spine, unresectable anaplastic astrocytoma s/p radiation.\"\n",
      "    },\n",
      "    {\n",
      "      \"criterion\": \"Age >= 16 years\",\n",
      "      \"label\": \"met\",\n",
      "      \"evidence\": \"Patient is a 45-year-old man\"\n",
      "    },\n",
      "    {\n",
      "      \"criterion\": \"Eastern Cooperative Oncology Group (ECOG) performance status =< 1\",\n",
      "      \"label\": \"unknown\",\n",
      "      \"evidence\": \"none\"\n",
      "    },\n",
      "    {\n",
      "      \"criterion\": \"Hemoglobin > 9.0 g/dL\",\n",
      "      \"label\": \"met\",\n",
      "      \"evidence\": \"none\"\n",
      "    },\n",
      "    {\n",
      "      \"criterion\": \"Leukocytes\n",
      "\n",
      "Parsed JSON keys: ['trial_id', 'overall_assessment', 'inclusion', 'exclusion', 'notes']\n",
      "\n",
      "Overall assessment: likely_eligible\n",
      "\n",
      "Inclusion items: 12\n",
      "Exclusion items: 4\n",
      "\n",
      "--- Parsed JSON ---\n",
      "{\n",
      "  \"trial_id\": \"NCT03528642\",\n",
      "  \"overall_assessment\": \"likely_eligible\",\n",
      "  \"inclusion\": [\n",
      "    {\n",
      "      \"criterion\": \"histopathologic or molecular confirmation of either IDH-mutant DA or IDH-mutant AA\",\n",
      "      \"label\": \"met\",\n",
      "      \"evidence\": \"The tumor is located in the T-L spine, unresectable anaplastic astrocytoma s/p radiation.\"\n",
      "    },\n",
      "    {\n",
      "      \"criterion\": \"Age >= 16 years\",\n",
      "      \"label\": \"met\",\n",
      "      \"evidence\": \"Patient is a 45-year-old man\"\n",
      "    },\n",
      "    {\n",
      "      \"criterion\": \"Eastern Cooperative Oncology Group (ECOG) performance status =< 1\",\n",
      "      \"label\": \"unknown\",\n",
      "      \"evidence\": \"none\"\n",
      "    },\n",
      "    {\n",
      "      \"criterion\": \"Hemoglobin > 9.0 g/dL\",\n",
      "      \"label\": \"met\",\n",
      "      \"evidence\": \"none\"\n",
      "    },\n",
      "    {\n",
      "      \"criterion\": \"Leukocytes >= 3.0 x 10^9/L\",\n",
      "      \"label\": \"unknown\",\n",
      "      \"evidence\": \"none\"\n",
      "    },\n",
      "    {\n",
      "      \"criterion\": \"Absolute neutrophil count >= 1.5 x 10^9/L\",\n",
      "      \"label\": \"unknown\",\n",
      "      \"evidence\": \"none\"\n",
      "    },\n",
      "    {\n",
      "      \"criterion\": \"Platelets >= 100 x 10^9/L\",\n",
      "      \"label\": \"met\",\n",
      "      \"evidence\": \"none\"\n",
      "    },\n",
      "    {\n",
      "      \"criterion\": \"International normalized ratio (INR) =< 1.5 x upper limit of normal (ULN)\",\n",
      "      \"label\": \"unknown\",\n",
      "      \"evidence\": \"none\"\n",
      "    },\n",
      "    {\n",
      "      \"criterion\": \"Partial thromboplastin time (PTT) or activated partial thromboplastin time (APTT) =< 1.5 x ULN\",\n",
      "      \"label\": \"unknown\",\n",
      "      \"evidence\": \"none\"\n",
      "    },\n",
      "    {\n",
      "      \"criterion\": \"Total bilirubin =< 1.5 x institutional ULN and < 3 mg/dL for patients with Gilbert's disease\",\n",
      "      \"label\": \"met\",\n",
      "      \"evidence\": \"none\"\n",
      "    },\n",
      "    {\n",
      "      \"criterion\": \"Aspartate aminotransferase (AST) (serum glutamic-oxaloacetic transaminase [SGOT]) & alanine aminotransferase (ALT) (serum glutamate pyruvate transaminase [SGPT]) =< 3 x institutional ULN\",\n",
      "      \"label\": \"unknown\",\n",
      "      \"evidence\": \"none\"\n",
      "    },\n",
      "    {\n",
      "      \"criterion\": \"Creatinine =< 1.5 x institutional ULN or creatinine clearance >= 60 mL/minute\",\n",
      "      \"label\": \"met\",\n",
      "      \"evidence\": \"none\"\n",
      "    }\n",
      "  ],\n",
      "  \"exclusion\": [\n",
      "    {\n",
      "      \"criterion\": \"Patients must not have received prior chemotherapy to treat the glioma.\",\n",
      "      \"label\": \"not_met\",\n",
      "      \"evidence\": \"The tumor is located in the T-L spine, unresectable anaplastic astrocytoma s/p radiation.\"\n",
      "    },\n",
      "    {\n",
      "      \"criterion\": \"Patient must not have received prior radiation therapy to the brain. Prior radiation therapy to the head and neck is also excluded if radiation fields overlap.\",\n",
      "      \"label\": \"met\",\n",
      "      \"evidence\": \"The tumor is located in the T-L spine, unresectable anaplastic astrocytoma s/p radiation.\"\n",
      "    },\n",
      "    {\n",
      "      \"criterion\": \"Patient must have no evidence of either infratentorial or spinal involvement with tumor.\",\n",
      "      \"label\": \"not_met\",\n",
      "      \"evidence\": \"The tumor is located in the T-L spine, unresectable anaplastic astrocytoma s/p radiation.\"\n",
      "    },\n",
      "    {\n",
      "      \"criterion\": \"Patients who are unable to swallow tablets.\",\n",
      "      \"label\": \"unknown\",\n",
      "      \"evidence\": \"none\"\n",
      "    }\n",
      "  ]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from textwrap import shorten\n",
    "\n",
    "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "OLLAMA_MODEL = \"llama3.1:8b\"\n",
    "\n",
    "def ollama_generate(prompt: str, model: str = OLLAMA_MODEL, temperature: float = 0.0) -> str:\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": temperature\n",
    "        }\n",
    "    }\n",
    "    r = requests.post(OLLAMA_URL, json=payload, timeout=300)\n",
    "    r.raise_for_status()\n",
    "    return r.json()[\"response\"]\n",
    "\n",
    "def build_matching_prompt(patient_text: str, inclusion: list, exclusion: list, trial_id: str) -> str:\n",
    "    # Keep prompt compact but structured\n",
    "    inc = \"\\n\".join([f\"- {c}\" for c in inclusion[:60]])  # cap to avoid huge prompts\n",
    "    exc = \"\\n\".join([f\"- {c}\" for c in exclusion[:60]])\n",
    "\n",
    "    return f\"\"\"\n",
    "You are a clinical trial eligibility matching assistant.\n",
    "Given a patient description and a trial's inclusion/exclusion criteria, determine eligibility evidence.\n",
    "\n",
    "Return ONLY valid JSON with this exact schema:\n",
    "{{\n",
    "  \"trial_id\": \"{trial_id}\",\n",
    "  \"overall_assessment\": \"likely_eligible\" | \"likely_ineligible\" | \"uncertain\",\n",
    "  \"inclusion\": [\n",
    "    {{\n",
    "      \"criterion\": \"...\",\n",
    "      \"label\": \"met\" | \"not_met\" | \"unknown\",\n",
    "      \"evidence\": \"short quote or phrase from patient text that supports your label, or 'none'\"\n",
    "    }}\n",
    "  ],\n",
    "  \"exclusion\": [\n",
    "    {{\n",
    "      \"criterion\": \"...\",\n",
    "      \"label\": \"triggers\" | \"does_not_trigger\" | \"unknown\",\n",
    "      \"evidence\": \"short quote or phrase from patient text that supports your label, or 'none'\"\n",
    "    }}\n",
    "  ],\n",
    "  \"notes\": \"1-2 sentences about key unknowns\"\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- Use ONLY the patient text. Do NOT assume missing facts.\n",
    "- If patient text doesn't mention something, label it unknown.\n",
    "- Be conservative: if any exclusion likely triggers, overall_assessment should be likely_ineligible.\n",
    "- Include at most 12 inclusion items and 8 exclusion items (pick the most important/decisive ones).\n",
    "\n",
    "PATIENT:\n",
    "{patient_text}\n",
    "\n",
    "TRIAL INCLUSION CRITERIA (subset):\n",
    "{inc if inc.strip() else \"- (none found)\"}\n",
    "\n",
    "TRIAL EXCLUSION CRITERIA (subset):\n",
    "{exc if exc.strip() else \"- (none found)\"}\n",
    "\"\"\".strip()\n",
    "\n",
    "def safe_json_load(s: str):\n",
    "    \"\"\"\n",
    "    Tries hard to parse JSON even if model adds extra text.\n",
    "    \"\"\"\n",
    "    s = s.strip()\n",
    "    # If it already starts with { ... }, try direct\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Extract the first {...} block\n",
    "    start = s.find(\"{\")\n",
    "    end = s.rfind(\"}\")\n",
    "    if start != -1 and end != -1 and end > start:\n",
    "        try:\n",
    "            return json.loads(s[start:end+1])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    raise ValueError(\"Could not parse JSON from model output.\")\n",
    "\n",
    "# ---- pick one topic and one trial to test end-to-end ----\n",
    "topic_id = \"1\"\n",
    "trial_id = \"NCT03528642\"\n",
    "\n",
    "patient_text = queries_df.loc[queries_df[\"topic_id\"].astype(str) == topic_id, \"text\"].iloc[0]\n",
    "trial_text = get_trial_text(trial_id)\n",
    "elig = extract_eligibility(trial_text)\n",
    "\n",
    "prompt = build_matching_prompt(\n",
    "    patient_text=patient_text,\n",
    "    inclusion=elig[\"inclusion\"],\n",
    "    exclusion=elig[\"exclusion\"],\n",
    "    trial_id=trial_id\n",
    ")\n",
    "\n",
    "print(\"Patient preview:\", shorten(patient_text.replace(\"\\n\", \" \"), width=220, placeholder=\"...\"))\n",
    "print(\"Trial:\", trial_id, \"| inclusion:\", len(elig[\"inclusion\"]), \"| exclusion:\", len(elig[\"exclusion\"]))\n",
    "print(\"\\n--- Sending to Ollama ---\")\n",
    "\n",
    "raw = ollama_generate(prompt, temperature=0.0)\n",
    "print(\"\\n--- Raw model output (first 800 chars) ---\")\n",
    "print(raw[:800])\n",
    "\n",
    "result = safe_json_load(raw)\n",
    "print(\"\\nParsed JSON keys:\", list(result.keys()))\n",
    "print(\"\\nOverall assessment:\", result.get(\"overall_assessment\"))\n",
    "print(\"\\nInclusion items:\", len(result.get(\"inclusion\", [])))\n",
    "print(\"Exclusion items:\", len(result.get(\"exclusion\", [])))\n",
    "\n",
    "# show the parsed JSON (pretty)\n",
    "print(\"\\n--- Parsed JSON ---\")\n",
    "print(json.dumps(result, indent=2)[:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1c34667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished matching + scoring for topic: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>bm25_rank</th>\n",
       "      <th>bm25_score</th>\n",
       "      <th>overall_assessment</th>\n",
       "      <th>agg_score</th>\n",
       "      <th>n_inclusion_items</th>\n",
       "      <th>n_exclusion_items</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00734682</td>\n",
       "      <td>9</td>\n",
       "      <td>276.883413</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>Unclear if patient has fully recovered from pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00968240</td>\n",
       "      <td>7</td>\n",
       "      <td>279.294295</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Patient's expected survival and hematologic re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00841555</td>\n",
       "      <td>6</td>\n",
       "      <td>286.027940</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Patient's Karnofsky score and prior chemothera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT03528642</td>\n",
       "      <td>1</td>\n",
       "      <td>293.930154</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>Patient's history of hypertension and chronic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT03633552</td>\n",
       "      <td>5</td>\n",
       "      <td>286.098323</td>\n",
       "      <td>likely_ineligible</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Key unknowns include the patient's Karnofsky P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00003176</td>\n",
       "      <td>2</td>\n",
       "      <td>290.582836</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00003537</td>\n",
       "      <td>10</td>\n",
       "      <td>276.226250</td>\n",
       "      <td>likely_ineligible</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Patient's condition and treatment history are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00089427</td>\n",
       "      <td>8</td>\n",
       "      <td>277.892832</td>\n",
       "      <td>likely_ineligible</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>Unknown Karnofsky Performance Scale score and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT02942264</td>\n",
       "      <td>3</td>\n",
       "      <td>288.751092</td>\n",
       "      <td>likely_ineligible</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>Patient's history of anaplastic astrocytoma an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT01466686</td>\n",
       "      <td>4</td>\n",
       "      <td>287.161880</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>ECOG performance status, organ and marrow func...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  topic_id     trial_id  bm25_rank  bm25_score overall_assessment  agg_score  \\\n",
       "0        1  NCT00734682          9  276.883413    likely_eligible        5.0   \n",
       "1        1  NCT00968240          7  279.294295    likely_eligible        4.5   \n",
       "2        1  NCT00841555          6  286.027940    likely_eligible        3.5   \n",
       "3        1  NCT03528642          1  293.930154    likely_eligible        3.0   \n",
       "4        1  NCT03633552          5  286.098323  likely_ineligible        1.0   \n",
       "5        1  NCT00003176          2  290.582836    likely_eligible        0.0   \n",
       "6        1  NCT00003537         10  276.226250  likely_ineligible        0.0   \n",
       "7        1  NCT00089427          8  277.892832  likely_ineligible       -2.0   \n",
       "8        1  NCT02942264          3  288.751092  likely_ineligible       -5.0   \n",
       "9        1  NCT01466686          4  287.161880    likely_eligible       -8.0   \n",
       "\n",
       "   n_inclusion_items  n_exclusion_items  \\\n",
       "0                  7                  3   \n",
       "1                  8                  3   \n",
       "2                  3                  3   \n",
       "3                 12                  4   \n",
       "4                  4                  5   \n",
       "5                  0                  0   \n",
       "6                  0                  0   \n",
       "7                  6                  2   \n",
       "8                  9                  2   \n",
       "9                 12                  8   \n",
       "\n",
       "                                               notes  \n",
       "0  Unclear if patient has fully recovered from pr...  \n",
       "1  Patient's expected survival and hematologic re...  \n",
       "2  Patient's Karnofsky score and prior chemothera...  \n",
       "3  Patient's history of hypertension and chronic ...  \n",
       "4  Key unknowns include the patient's Karnofsky P...  \n",
       "5                                                     \n",
       "6  Patient's condition and treatment history are ...  \n",
       "7  Unknown Karnofsky Performance Scale score and ...  \n",
       "8  Patient's history of anaplastic astrocytoma an...  \n",
       "9  ECOG performance status, organ and marrow func...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# --------- settings ----------\n",
    "TOPIC_ID = \"1\"      # change later to test other topics\n",
    "TOP_N = 10          # start small; later we can do 50 or 100\n",
    "SLEEP_SEC = 0.0     # set to e.g. 0.2 if Ollama gets overloaded\n",
    "\n",
    "# --------- fetch patient text ----------\n",
    "patient_text = queries_df.loc[queries_df[\"topic_id\"].astype(str) == TOPIC_ID, \"text\"].iloc[0]\n",
    "\n",
    "# --------- choose top-N trials from retrieval ----------\n",
    "top_trials = (\n",
    "    run_df[run_df[\"topic_id\"].astype(str) == TOPIC_ID]\n",
    "    .sort_values(\"rank\")\n",
    "    .head(TOP_N)[[\"doc_id\", \"rank\", \"score\"]]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "def score_match(result_json: dict) -> float:\n",
    "    \"\"\"\n",
    "    Simple deterministic scoring (baseline aggregator).\n",
    "    - Inclusion: met +1, unknown 0, not_met -1\n",
    "    - Exclusion: triggers/met -4, unknown 0, does_not_trigger/not_met +0.5\n",
    "    \"\"\"\n",
    "    score = 0.0\n",
    "\n",
    "    inc = result_json.get(\"inclusion\", [])\n",
    "    exc = result_json.get(\"exclusion\", [])\n",
    "\n",
    "    for it in inc:\n",
    "        lab = (it.get(\"label\") or \"\").strip().lower()\n",
    "        if lab == \"met\":\n",
    "            score += 1.0\n",
    "        elif lab == \"not_met\":\n",
    "            score -= 1.0\n",
    "        else:  # unknown\n",
    "            score += 0.0\n",
    "\n",
    "    for it in exc:\n",
    "        lab = (it.get(\"label\") or \"\").strip().lower()\n",
    "        # allow either schema wordings (some models say met/not_met)\n",
    "        if lab in {\"triggers\", \"met\"}:\n",
    "            score -= 4.0\n",
    "        elif lab in {\"does_not_trigger\", \"not_met\"}:\n",
    "            score += 0.5\n",
    "        else:\n",
    "            score += 0.0\n",
    "\n",
    "    return score\n",
    "\n",
    "# --------- run matching over Top-N ----------\n",
    "results = []\n",
    "for row in top_trials.itertuples(index=False):\n",
    "    trial_id = row.doc_id\n",
    "\n",
    "    trial_text = get_trial_text(trial_id)\n",
    "    elig = extract_eligibility(trial_text)\n",
    "\n",
    "    prompt = build_matching_prompt(\n",
    "        patient_text=patient_text,\n",
    "        inclusion=elig[\"inclusion\"],\n",
    "        exclusion=elig[\"exclusion\"],\n",
    "        trial_id=trial_id\n",
    "    )\n",
    "\n",
    "    raw = ollama_generate(prompt, temperature=0.0)\n",
    "    match_json = safe_json_load(raw)\n",
    "\n",
    "    agg_score = score_match(match_json)\n",
    "\n",
    "    results.append({\n",
    "        \"topic_id\": TOPIC_ID,\n",
    "        \"trial_id\": trial_id,\n",
    "        \"bm25_rank\": int(row.rank),\n",
    "        \"bm25_score\": float(row.score),\n",
    "        \"overall_assessment\": match_json.get(\"overall_assessment\"),\n",
    "        \"agg_score\": agg_score,\n",
    "        \"n_inclusion_items\": len(match_json.get(\"inclusion\", [])),\n",
    "        \"n_exclusion_items\": len(match_json.get(\"exclusion\", [])),\n",
    "        \"notes\": match_json.get(\"notes\", \"\")\n",
    "    })\n",
    "\n",
    "    if SLEEP_SEC > 0:\n",
    "        time.sleep(SLEEP_SEC)\n",
    "\n",
    "rank_df = pd.DataFrame(results).sort_values([\"agg_score\", \"bm25_score\"], ascending=[False, False]).reset_index(drop=True)\n",
    "\n",
    "print(\"Finished matching + scoring for topic:\", TOPIC_ID)\n",
    "display(rank_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9b4f54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching Top-50 for topic 1: 100%|██████████| 50/50 [15:49<00:00, 19.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch matching complete\n",
      "Saved new JSON files: 49\n",
      "Skipped (already cached): 0\n",
      "Errors: 1\n",
      "Cache folder: C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\matches\\topic_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --------- settings ----------\n",
    "TOPIC_ID = \"1\"\n",
    "TOP_K = 50  # start with 50; later increase to 100\n",
    "CACHE_DIR = Path(r\"C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\matches\")\n",
    "RUN_TAG = \"llama31_8b\"\n",
    "\n",
    "topic_dir = CACHE_DIR / f\"topic_{TOPIC_ID}\"\n",
    "topic_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --------- patient text ----------\n",
    "patient_text = queries_df.loc[queries_df[\"topic_id\"].astype(str) == TOPIC_ID, \"text\"].iloc[0]\n",
    "\n",
    "# --------- top-K trials from retrieval ----------\n",
    "top_trials = (\n",
    "    run_df[run_df[\"topic_id\"].astype(str) == TOPIC_ID]\n",
    "    .sort_values(\"rank\")\n",
    "    .head(TOP_K)[[\"doc_id\", \"rank\", \"score\"]]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "def cache_path_for(trial_id: str) -> Path:\n",
    "    return topic_dir / f\"{trial_id}_{RUN_TAG}.json\"\n",
    "\n",
    "def run_one_match(topic_id: str, trial_id: str) -> dict:\n",
    "    trial_text = get_trial_text(trial_id)\n",
    "    elig = extract_eligibility(trial_text)\n",
    "\n",
    "    prompt = build_matching_prompt(\n",
    "        patient_text=patient_text,\n",
    "        inclusion=elig[\"inclusion\"],\n",
    "        exclusion=elig[\"exclusion\"],\n",
    "        trial_id=trial_id\n",
    "    )\n",
    "\n",
    "    raw = ollama_generate(prompt, temperature=0.0)\n",
    "    match_json = safe_json_load(raw)\n",
    "\n",
    "    # add minimal metadata so files are self-contained\n",
    "    match_json[\"_meta\"] = {\n",
    "        \"topic_id\": topic_id,\n",
    "        \"trial_id\": trial_id,\n",
    "        \"model\": OLLAMA_MODEL,\n",
    "        \"run_tag\": RUN_TAG\n",
    "    }\n",
    "    return match_json\n",
    "\n",
    "# --------- batch with caching ----------\n",
    "saved = 0\n",
    "skipped = 0\n",
    "errors = 0\n",
    "\n",
    "for row in tqdm(top_trials.itertuples(index=False), total=len(top_trials), desc=f\"Matching Top-{TOP_K} for topic {TOPIC_ID}\"):\n",
    "    trial_id = row.doc_id\n",
    "    out_path = cache_path_for(trial_id)\n",
    "\n",
    "    if out_path.exists():\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        match_json = run_one_match(TOPIC_ID, trial_id)\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(match_json, f, indent=2)\n",
    "        saved += 1\n",
    "    except Exception as e:\n",
    "        errors += 1\n",
    "        err_path = topic_dir / f\"{trial_id}_{RUN_TAG}.error.txt\"\n",
    "        with open(err_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(str(e))\n",
    "        continue\n",
    "\n",
    "print(\"\\nBatch matching complete\")\n",
    "print(\"Saved new JSON files:\", saved)\n",
    "print(\"Skipped (already cached):\", skipped)\n",
    "print(\"Errors:\", errors)\n",
    "print(\"Cache folder:\", str(topic_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f487c856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cached matches: 49\n",
      "Missing (due to errors / not cached): 1\n",
      "\n",
      "Saved reranked run to:\n",
      "C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\trialgpt_llama31_8b_trec2021_topic1_top50.run\n",
      "\n",
      "Saved rerank table to:\n",
      "C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\trialgpt_llama31_8b_trec2021_topic1_top50_table.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>bm25_rank</th>\n",
       "      <th>bm25_score</th>\n",
       "      <th>overall_assessment</th>\n",
       "      <th>agg_score</th>\n",
       "      <th>n_inclusion_items</th>\n",
       "      <th>n_exclusion_items</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT03896568</td>\n",
       "      <td>21</td>\n",
       "      <td>262.807820</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>6.5</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>The patient has a history of anaplastic astroc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00360828</td>\n",
       "      <td>37</td>\n",
       "      <td>255.430346</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>6.5</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>Predicted life expectancy and ANC, Platelets, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00704080</td>\n",
       "      <td>20</td>\n",
       "      <td>262.849991</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>Unknowns include adequate organ and bone marro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00783393</td>\n",
       "      <td>46</td>\n",
       "      <td>253.370398</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Unknown: tissue samples available for Central ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00047879</td>\n",
       "      <td>14</td>\n",
       "      <td>267.152148</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>5.5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>Unknown Karnofsky performance status and adequ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00458731</td>\n",
       "      <td>47</td>\n",
       "      <td>253.129568</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>5.5</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>Key unknowns include the patient's total bilir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00734682</td>\n",
       "      <td>9</td>\n",
       "      <td>276.883413</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>Unclear if patient has fully recovered from pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00504660</td>\n",
       "      <td>11</td>\n",
       "      <td>269.024049</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Patient's history of anaplastic astrocytoma an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00859222</td>\n",
       "      <td>32</td>\n",
       "      <td>256.908038</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT01847235</td>\n",
       "      <td>40</td>\n",
       "      <td>253.914335</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>Key unknowns include the patient's ECOG perfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT01295944</td>\n",
       "      <td>50</td>\n",
       "      <td>252.494195</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>Unknown Karnofsky performance status, adequate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00968240</td>\n",
       "      <td>7</td>\n",
       "      <td>279.294295</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Patient's expected survival and hematologic re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00841555</td>\n",
       "      <td>6</td>\n",
       "      <td>286.027940</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Patient's Karnofsky score and prior chemothera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00761280</td>\n",
       "      <td>27</td>\n",
       "      <td>260.078628</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>3.5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>Patient has a complex medical history, includi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT03528642</td>\n",
       "      <td>1</td>\n",
       "      <td>293.930154</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>Patient's history of hypertension and chronic ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id     trial_id  bm25_rank  bm25_score overall_assessment  agg_score  \\\n",
       "0         1  NCT03896568         21  262.807820    likely_eligible        6.5   \n",
       "1         1  NCT00360828         37  255.430346    likely_eligible        6.5   \n",
       "2         1  NCT00704080         20  262.849991    likely_eligible        6.0   \n",
       "3         1  NCT00783393         46  253.370398    likely_eligible        6.0   \n",
       "4         1  NCT00047879         14  267.152148    likely_eligible        5.5   \n",
       "5         1  NCT00458731         47  253.129568    likely_eligible        5.5   \n",
       "6         1  NCT00734682          9  276.883413    likely_eligible        5.0   \n",
       "7         1  NCT00504660         11  269.024049    likely_eligible        5.0   \n",
       "8         1  NCT00859222         32  256.908038    likely_eligible        5.0   \n",
       "9         1  NCT01847235         40  253.914335    likely_eligible        5.0   \n",
       "10        1  NCT01295944         50  252.494195    likely_eligible        5.0   \n",
       "11        1  NCT00968240          7  279.294295    likely_eligible        4.5   \n",
       "12        1  NCT00841555          6  286.027940    likely_eligible        3.5   \n",
       "13        1  NCT00761280         27  260.078628    likely_eligible        3.5   \n",
       "14        1  NCT03528642          1  293.930154    likely_eligible        3.0   \n",
       "\n",
       "    n_inclusion_items  n_exclusion_items  \\\n",
       "0                  16                  6   \n",
       "1                  12                  4   \n",
       "2                   7                  5   \n",
       "3                   8                  3   \n",
       "4                   9                  5   \n",
       "5                  12                  8   \n",
       "6                   7                  3   \n",
       "7                   6                  6   \n",
       "8                  14                 15   \n",
       "9                  12                  3   \n",
       "10                 12                  3   \n",
       "11                  8                  3   \n",
       "12                  3                  3   \n",
       "13                 12                  7   \n",
       "14                 12                  4   \n",
       "\n",
       "                                                notes  \n",
       "0   The patient has a history of anaplastic astroc...  \n",
       "1   Predicted life expectancy and ANC, Platelets, ...  \n",
       "2   Unknowns include adequate organ and bone marro...  \n",
       "3   Unknown: tissue samples available for Central ...  \n",
       "4   Unknown Karnofsky performance status and adequ...  \n",
       "5   Key unknowns include the patient's total bilir...  \n",
       "6   Unclear if patient has fully recovered from pr...  \n",
       "7   Patient's history of anaplastic astrocytoma an...  \n",
       "8                                                      \n",
       "9   Key unknowns include the patient's ECOG perfor...  \n",
       "10  Unknown Karnofsky performance status, adequate...  \n",
       "11  Patient's expected survival and hematologic re...  \n",
       "12  Patient's Karnofsky score and prior chemothera...  \n",
       "13  Patient has a complex medical history, includi...  \n",
       "14  Patient's history of hypertension and chronic ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "TOPIC_ID = \"1\"\n",
    "TOP_K = 50\n",
    "RUN_TAG = \"llama31_8b\"\n",
    "\n",
    "CACHE_DIR = Path(r\"C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\matches\") / f\"topic_{TOPIC_ID}\"\n",
    "OUT_DIR = Path(r\"C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "rerank_run_path = OUT_DIR / f\"trialgpt_{RUN_TAG}_trec2021_topic{TOPIC_ID}_top{TOP_K}.run\"\n",
    "rerank_table_path = OUT_DIR / f\"trialgpt_{RUN_TAG}_trec2021_topic{TOPIC_ID}_top{TOP_K}_table.csv\"\n",
    "\n",
    "# --- helper: same scoring as before ---\n",
    "def score_match(result_json: dict) -> float:\n",
    "    score = 0.0\n",
    "    inc = result_json.get(\"inclusion\", [])\n",
    "    exc = result_json.get(\"exclusion\", [])\n",
    "\n",
    "    for it in inc:\n",
    "        lab = (it.get(\"label\") or \"\").strip().lower()\n",
    "        if lab == \"met\":\n",
    "            score += 1.0\n",
    "        elif lab == \"not_met\":\n",
    "            score -= 1.0\n",
    "\n",
    "    for it in exc:\n",
    "        lab = (it.get(\"label\") or \"\").strip().lower()\n",
    "        if lab in {\"triggers\", \"met\"}:\n",
    "            score -= 4.0\n",
    "        elif lab in {\"does_not_trigger\", \"not_met\"}:\n",
    "            score += 0.5\n",
    "\n",
    "    return score\n",
    "\n",
    "# --- read top-K from retrieval (same candidate set) ---\n",
    "top_trials = (\n",
    "    run_df[run_df[\"topic_id\"].astype(str) == TOPIC_ID]\n",
    "    .sort_values(\"rank\")\n",
    "    .head(TOP_K)[[\"doc_id\", \"rank\", \"score\"]]\n",
    "    .rename(columns={\"doc_id\": \"trial_id\", \"rank\": \"bm25_rank\", \"score\": \"bm25_score\"})\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# --- load cached JSONs ---\n",
    "rows = []\n",
    "missing = 0\n",
    "\n",
    "for r in top_trials.itertuples(index=False):\n",
    "    trial_id = r.trial_id\n",
    "    json_path = CACHE_DIR / f\"{trial_id}_{RUN_TAG}.json\"\n",
    "\n",
    "    if not json_path.exists():\n",
    "        missing += 1\n",
    "        continue\n",
    "\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        match_json = json.load(f)\n",
    "\n",
    "    agg = score_match(match_json)\n",
    "\n",
    "    rows.append({\n",
    "        \"topic_id\": TOPIC_ID,\n",
    "        \"trial_id\": trial_id,\n",
    "        \"bm25_rank\": int(r.bm25_rank),\n",
    "        \"bm25_score\": float(r.bm25_score),\n",
    "        \"overall_assessment\": match_json.get(\"overall_assessment\", \"\"),\n",
    "        \"agg_score\": float(agg),\n",
    "        \"n_inclusion_items\": len(match_json.get(\"inclusion\", [])),\n",
    "        \"n_exclusion_items\": len(match_json.get(\"exclusion\", [])),\n",
    "        \"notes\": match_json.get(\"notes\", \"\")\n",
    "    })\n",
    "\n",
    "rank_df = pd.DataFrame(rows)\n",
    "rank_df = rank_df.sort_values([\"agg_score\", \"bm25_score\"], ascending=[False, False]).reset_index(drop=True)\n",
    "\n",
    "print(\"Loaded cached matches:\", len(rank_df))\n",
    "print(\"Missing (due to errors / not cached):\", missing)\n",
    "\n",
    "# --- assign new ranks and write a TREC run file (reranked) ---\n",
    "runname = f\"trialgpt_{RUN_TAG}\"\n",
    "with open(rerank_run_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, row in enumerate(rank_df.itertuples(index=False), start=1):\n",
    "        # Use agg_score as the run score (primary ranking signal)\n",
    "        f.write(f\"{TOPIC_ID} Q0 {row.trial_id} {i} {row.agg_score:.6f} {runname}\\n\")\n",
    "\n",
    "rank_df.to_csv(rerank_table_path, index=False)\n",
    "\n",
    "print(\"\\nSaved reranked run to:\")\n",
    "print(rerank_run_path)\n",
    "print(\"\\nSaved rerank table to:\")\n",
    "print(rerank_table_path)\n",
    "\n",
    "display(rank_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e62da03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved FULL reranked run to:\n",
      "C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\trialgpt_llama31_8b_trec2021_top100.run\n",
      "\n",
      "Saved coverage report to:\n",
      "C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\trialgpt_llama31_8b_trec2021_top100_coverage.csv\n",
      "\n",
      "Coverage summary:\n",
      "       matched_cached\n",
      "count       75.000000\n",
      "mean         0.653333\n",
      "std          5.658033\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max         49.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>candidates</th>\n",
       "      <th>matched_cached</th>\n",
       "      <th>missing_cached</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  topic_id  candidates  matched_cached  missing_cached\n",
       "0        1         100              49              51\n",
       "1        2         100               0             100\n",
       "2        3         100               0             100\n",
       "3        4         100               0             100\n",
       "4        5         100               0             100\n",
       "5        6         100               0             100\n",
       "6        7         100               0             100\n",
       "7        8         100               0             100\n",
       "8        9         100               0             100\n",
       "9       10         100               0             100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "TOP_K = 100\n",
    "RUN_TAG = \"llama31_8b\"\n",
    "\n",
    "# Where cached matches live:\n",
    "CACHE_BASE = Path(r\"C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\matches\")\n",
    "\n",
    "# Output files:\n",
    "OUT_DIR = Path(r\"C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "full_run_path = OUT_DIR / f\"trialgpt_{RUN_TAG}_trec2021_top{TOP_K}.run\"\n",
    "coverage_path = OUT_DIR / f\"trialgpt_{RUN_TAG}_trec2021_top{TOP_K}_coverage.csv\"\n",
    "\n",
    "def score_match(result_json: dict) -> float:\n",
    "    score = 0.0\n",
    "    inc = result_json.get(\"inclusion\", [])\n",
    "    exc = result_json.get(\"exclusion\", [])\n",
    "\n",
    "    for it in inc:\n",
    "        lab = (it.get(\"label\") or \"\").strip().lower()\n",
    "        if lab == \"met\":\n",
    "            score += 1.0\n",
    "        elif lab == \"not_met\":\n",
    "            score -= 1.0\n",
    "\n",
    "    for it in exc:\n",
    "        lab = (it.get(\"label\") or \"\").strip().lower()\n",
    "        if lab in {\"triggers\", \"met\"}:\n",
    "            score -= 4.0\n",
    "        elif lab in {\"does_not_trigger\", \"not_met\"}:\n",
    "            score += 0.5\n",
    "\n",
    "    return score\n",
    "\n",
    "runname = f\"trialgpt_{RUN_TAG}\"\n",
    "\n",
    "all_lines = []\n",
    "coverage_rows = []\n",
    "\n",
    "topic_ids = sorted(queries_df[\"topic_id\"].astype(str).unique(), key=lambda x: int(x))\n",
    "\n",
    "for topic_id in topic_ids:\n",
    "    # candidates from BM25 run_df (already have top100 per topic)\n",
    "    cands = (\n",
    "        run_df[run_df[\"topic_id\"].astype(str) == topic_id]\n",
    "        .sort_values(\"rank\")\n",
    "        .head(TOP_K)[[\"doc_id\", \"rank\", \"score\"]]\n",
    "        .rename(columns={\"doc_id\": \"trial_id\", \"rank\": \"bm25_rank\", \"score\": \"bm25_score\"})\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    topic_dir = CACHE_BASE / f\"topic_{topic_id}\"\n",
    "    matched = []\n",
    "    missing = 0\n",
    "\n",
    "    for r in cands.itertuples(index=False):\n",
    "        trial_id = r.trial_id\n",
    "        json_path = topic_dir / f\"{trial_id}_{RUN_TAG}.json\"\n",
    "\n",
    "        if not json_path.exists():\n",
    "            missing += 1\n",
    "            continue\n",
    "\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            match_json = json.load(f)\n",
    "\n",
    "        agg = score_match(match_json)\n",
    "\n",
    "        matched.append({\n",
    "            \"trial_id\": trial_id,\n",
    "            \"agg_score\": float(agg),\n",
    "            \"bm25_score\": float(r.bm25_score)\n",
    "        })\n",
    "\n",
    "    if len(matched) == 0:\n",
    "        # no cached matches for this topic yet; we will skip writing any lines for it\n",
    "        coverage_rows.append({\n",
    "            \"topic_id\": topic_id,\n",
    "            \"candidates\": len(cands),\n",
    "            \"matched_cached\": 0,\n",
    "            \"missing_cached\": missing\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    ranked = (\n",
    "        pd.DataFrame(matched)\n",
    "        .sort_values([\"agg_score\", \"bm25_score\"], ascending=[False, False])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Write TREC run lines for this topic\n",
    "    for rank, row in enumerate(ranked.itertuples(index=False), start=1):\n",
    "        all_lines.append(f\"{topic_id} Q0 {row.trial_id} {rank} {row.agg_score:.6f} {runname}\\n\")\n",
    "\n",
    "    coverage_rows.append({\n",
    "        \"topic_id\": topic_id,\n",
    "        \"candidates\": len(cands),\n",
    "        \"matched_cached\": len(ranked),\n",
    "        \"missing_cached\": missing\n",
    "    })\n",
    "\n",
    "# Save the run file\n",
    "with open(full_run_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(all_lines)\n",
    "\n",
    "coverage_df = pd.DataFrame(coverage_rows)\n",
    "coverage_df.to_csv(coverage_path, index=False)\n",
    "\n",
    "print(\"Saved FULL reranked run to:\")\n",
    "print(full_run_path)\n",
    "print(\"\\nSaved coverage report to:\")\n",
    "print(coverage_path)\n",
    "\n",
    "print(\"\\nCoverage summary:\")\n",
    "print(coverage_df[[\"matched_cached\"]].describe())\n",
    "display(coverage_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dc62f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test topics:  20%|██        | 1/5 [03:11<12:47, 191.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 1] saved=12 skipped=0 errors=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test topics:  40%|████      | 2/5 [06:29<09:45, 195.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 2] saved=16 skipped=0 errors=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test topics:  60%|██████    | 3/5 [09:53<06:38, 199.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 3] saved=15 skipped=0 errors=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test topics:  80%|████████  | 4/5 [13:16<03:20, 200.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 4] saved=13 skipped=0 errors=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test topics: 100%|██████████| 5/5 [16:32<00:00, 198.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 5] saved=18 skipped=0 errors=2\n",
      "\n",
      "✅ TEST MATCHING DONE\n",
      "Total saved: 74\n",
      "Total skipped: 0\n",
      "Total errors: 26\n",
      "Cache base: C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\matches_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------ TEST SETTINGS ------------------\n",
    "TEST_TOPICS = 5        # only 5 topics for testing\n",
    "TOP_K = 20             # only top-20 candidates per topic\n",
    "RUN_TAG = \"llama31_8b_test\"\n",
    "SLEEP_SEC = 0.0\n",
    "\n",
    "# Make generation faster + more consistent\n",
    "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "OLLAMA_MODEL = \"llama3.1:8b\"\n",
    "\n",
    "def ollama_generate(prompt: str, model: str = OLLAMA_MODEL, temperature: float = 0.0, num_predict: int = 450) -> str:\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": temperature,\n",
    "            \"num_predict\": num_predict,  # hard cap output tokens\n",
    "        }\n",
    "    }\n",
    "    r = requests.post(OLLAMA_URL, json=payload, timeout=300)\n",
    "    r.raise_for_status()\n",
    "    return r.json()[\"response\"]\n",
    "\n",
    "def build_matching_prompt(patient_text: str, inclusion: list, exclusion: list, trial_id: str) -> str:\n",
    "    # Smaller slices for faster testing\n",
    "    inc = \"\\n\".join([f\"- {c}\" for c in inclusion[:25]])\n",
    "    exc = \"\\n\".join([f\"- {c}\" for c in exclusion[:20]])\n",
    "\n",
    "    return f\"\"\"\n",
    "Return ONLY valid JSON (no markdown, no extra text).\n",
    "\n",
    "Schema:\n",
    "{{\n",
    "  \"trial_id\": \"{trial_id}\",\n",
    "  \"overall_assessment\": \"likely_eligible\" | \"likely_ineligible\" | \"uncertain\",\n",
    "  \"inclusion\": [{{\"criterion\":\"...\",\"label\":\"met|not_met|unknown\",\"evidence\":\"quote|none\"}}],\n",
    "  \"exclusion\":  [{{\"criterion\":\"...\",\"label\":\"triggers|does_not_trigger|unknown\",\"evidence\":\"quote|none\"}}],\n",
    "  \"notes\": \"short\"\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- Use ONLY patient text. If not stated, label unknown.\n",
    "- Pick at most 8 inclusion and 5 exclusion items (most decisive).\n",
    "\n",
    "PATIENT:\n",
    "{patient_text}\n",
    "\n",
    "INCLUSION (subset):\n",
    "{inc if inc.strip() else \"- (none found)\"}\n",
    "\n",
    "EXCLUSION (subset):\n",
    "{exc if exc.strip() else \"- (none found)\"}\n",
    "\"\"\".strip()\n",
    "\n",
    "def safe_json_load(s: str):\n",
    "    s = s.strip()\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except Exception:\n",
    "        pass\n",
    "    start = s.find(\"{\")\n",
    "    end = s.rfind(\"}\")\n",
    "    if start != -1 and end != -1 and end > start:\n",
    "        return json.loads(s[start:end+1])\n",
    "    raise ValueError(\"Could not parse JSON from model output.\")\n",
    "\n",
    "# ------------------ CACHE PATHS ------------------\n",
    "CACHE_BASE = Path(r\"C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\matches_test\")\n",
    "CACHE_BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def cache_path(topic_id: str, trial_id: str) -> Path:\n",
    "    topic_dir = CACHE_BASE / f\"topic_{topic_id}\"\n",
    "    topic_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return topic_dir / f\"{trial_id}_{RUN_TAG}.json\"\n",
    "\n",
    "def error_path(topic_id: str, trial_id: str) -> Path:\n",
    "    topic_dir = CACHE_BASE / f\"topic_{topic_id}\"\n",
    "    topic_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return topic_dir / f\"{trial_id}_{RUN_TAG}.error.txt\"\n",
    "\n",
    "# ------------------ RUN TEST MATCHING ------------------\n",
    "topic_ids = sorted(queries_df[\"topic_id\"].astype(str).unique(), key=lambda x: int(x))[:TEST_TOPICS]\n",
    "\n",
    "total_saved = total_skipped = total_errors = 0\n",
    "\n",
    "for topic_id in tqdm(topic_ids, desc=\"Test topics\"):\n",
    "    patient_text = queries_df.loc[queries_df[\"topic_id\"].astype(str) == topic_id, \"text\"].iloc[0]\n",
    "\n",
    "    cands = (\n",
    "        run_df[run_df[\"topic_id\"].astype(str) == topic_id]\n",
    "        .sort_values(\"rank\")\n",
    "        .head(TOP_K)[\"doc_id\"]\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "    saved = skipped = errors = 0\n",
    "    for trial_id in tqdm(cands, desc=f\"Topic {topic_id}\", leave=False):\n",
    "        out_json = cache_path(topic_id, trial_id)\n",
    "        if out_json.exists():\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            trial_text = get_trial_text(trial_id)\n",
    "            elig = extract_eligibility(trial_text)\n",
    "\n",
    "            prompt = build_matching_prompt(patient_text, elig[\"inclusion\"], elig[\"exclusion\"], trial_id)\n",
    "            raw = ollama_generate(prompt, temperature=0.0, num_predict=450)\n",
    "            match_json = safe_json_load(raw)\n",
    "\n",
    "            match_json[\"_meta\"] = {\"topic_id\": topic_id, \"trial_id\": trial_id, \"model\": OLLAMA_MODEL, \"run_tag\": RUN_TAG}\n",
    "            with open(out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(match_json, f, indent=2)\n",
    "\n",
    "            saved += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            errors += 1\n",
    "            with open(error_path(topic_id, trial_id), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(str(e))\n",
    "\n",
    "        if SLEEP_SEC > 0:\n",
    "            time.sleep(SLEEP_SEC)\n",
    "\n",
    "    total_saved += saved\n",
    "    total_skipped += skipped\n",
    "    total_errors += errors\n",
    "\n",
    "    print(f\"\\n[Topic {topic_id}] saved={saved} skipped={skipped} errors={errors}\")\n",
    "\n",
    "print(\"\\n✅ TEST MATCHING DONE\")\n",
    "print(\"Total saved:\", total_saved)\n",
    "print(\"Total skipped:\", total_skipped)\n",
    "print(\"Total errors:\", total_errors)\n",
    "print(\"Cache base:\", str(CACHE_BASE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c78a2b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved reranked TEST run to:\n",
      "C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\test_outputs\\trialgpt_llama31_8b_test_trec2021_5topics_top20.run\n",
      "\n",
      "✅ Saved table to:\n",
      "C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\test_outputs\\trialgpt_llama31_8b_test_trec2021_5topics_top20_table.csv\n",
      "\n",
      "✅ Saved coverage to:\n",
      "C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\test_outputs\\trialgpt_llama31_8b_test_trec2021_5topics_top20_coverage.csv\n",
      "\n",
      "Coverage:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>candidates</th>\n",
       "      <th>matched_cached</th>\n",
       "      <th>missing_cached</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  topic_id  candidates  matched_cached  missing_cached\n",
       "0        1          20              12               8\n",
       "1        2          20              16               4\n",
       "2        3          20              15               5\n",
       "3        4          20              13               7\n",
       "4        5          20              18               2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample reranked rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>agg_score</th>\n",
       "      <th>bm25_score</th>\n",
       "      <th>bm25_rank</th>\n",
       "      <th>overall_assessment</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00362570</td>\n",
       "      <td>4.5</td>\n",
       "      <td>267.891473</td>\n",
       "      <td>12</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>Patient has a history of anaplastic astrocytom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT02942264</td>\n",
       "      <td>3.5</td>\n",
       "      <td>288.751092</td>\n",
       "      <td>3</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>Patient has a history of anaplastic astrocytom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00976313</td>\n",
       "      <td>1.5</td>\n",
       "      <td>264.269625</td>\n",
       "      <td>18</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>Patient has a history of anaplastic astrocytom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00003176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290.582836</td>\n",
       "      <td>2</td>\n",
       "      <td>likely_ineligible</td>\n",
       "      <td>Patient has unresectable anaplastic astrocytom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00003537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>276.226250</td>\n",
       "      <td>10</td>\n",
       "      <td>likely_ineligible</td>\n",
       "      <td>Patient has unresectable anaplastic astrocytom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00003775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>267.316937</td>\n",
       "      <td>13</td>\n",
       "      <td>likely_ineligible</td>\n",
       "      <td>Patient has unresectable anaplastic astrocytom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00052624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.655959</td>\n",
       "      <td>16</td>\n",
       "      <td>likely_ineligible</td>\n",
       "      <td>Patient has unresectable anaplastic astrocytom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00028795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.555911</td>\n",
       "      <td>17</td>\n",
       "      <td>likely_ineligible</td>\n",
       "      <td>Patient has unresectable anaplastic astrocytom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00004080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>262.940941</td>\n",
       "      <td>19</td>\n",
       "      <td>likely_ineligible</td>\n",
       "      <td>Patient has unresectable anaplastic astrocytom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00968240</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>279.294295</td>\n",
       "      <td>7</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>The patient has a history of anaplastic astroc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT00089427</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>277.892832</td>\n",
       "      <td>8</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>NCT03633552</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>286.098323</td>\n",
       "      <td>5</td>\n",
       "      <td>likely_ineligible</td>\n",
       "      <td>Patient has a history of anaplastic astrocytom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>NCT01272388</td>\n",
       "      <td>6.5</td>\n",
       "      <td>373.670864</td>\n",
       "      <td>13</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>NCT01575249</td>\n",
       "      <td>5.5</td>\n",
       "      <td>377.136854</td>\n",
       "      <td>11</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td>48 M with a h/o HTN hyperlipidemia, bicuspid a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>NCT04300686</td>\n",
       "      <td>5.0</td>\n",
       "      <td>408.073648</td>\n",
       "      <td>2</td>\n",
       "      <td>likely_eligible</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id     trial_id  agg_score  bm25_score  bm25_rank overall_assessment  \\\n",
       "0         1  NCT00362570        4.5  267.891473         12    likely_eligible   \n",
       "1         1  NCT02942264        3.5  288.751092          3    likely_eligible   \n",
       "2         1  NCT00976313        1.5  264.269625         18    likely_eligible   \n",
       "3         1  NCT00003176        0.0  290.582836          2  likely_ineligible   \n",
       "4         1  NCT00003537        0.0  276.226250         10  likely_ineligible   \n",
       "5         1  NCT00003775        0.0  267.316937         13  likely_ineligible   \n",
       "6         1  NCT00052624        0.0  264.655959         16  likely_ineligible   \n",
       "7         1  NCT00028795        0.0  264.555911         17  likely_ineligible   \n",
       "8         1  NCT00004080        0.0  262.940941         19  likely_ineligible   \n",
       "9         1  NCT00968240       -3.0  279.294295          7    likely_eligible   \n",
       "10        1  NCT00089427       -5.5  277.892832          8    likely_eligible   \n",
       "11        1  NCT03633552       -6.0  286.098323          5  likely_ineligible   \n",
       "12        2  NCT01272388        6.5  373.670864         13    likely_eligible   \n",
       "13        2  NCT01575249        5.5  377.136854         11    likely_eligible   \n",
       "14        2  NCT04300686        5.0  408.073648          2    likely_eligible   \n",
       "\n",
       "                                                notes  \n",
       "0   Patient has a history of anaplastic astrocytom...  \n",
       "1   Patient has a history of anaplastic astrocytom...  \n",
       "2   Patient has a history of anaplastic astrocytom...  \n",
       "3   Patient has unresectable anaplastic astrocytom...  \n",
       "4   Patient has unresectable anaplastic astrocytom...  \n",
       "5   Patient has unresectable anaplastic astrocytom...  \n",
       "6   Patient has unresectable anaplastic astrocytom...  \n",
       "7   Patient has unresectable anaplastic astrocytom...  \n",
       "8   Patient has unresectable anaplastic astrocytom...  \n",
       "9   The patient has a history of anaplastic astroc...  \n",
       "10                                                     \n",
       "11  Patient has a history of anaplastic astrocytom...  \n",
       "12                                              short  \n",
       "13  48 M with a h/o HTN hyperlipidemia, bicuspid a...  \n",
       "14                                                     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# --------- must match the test cell settings ----------\n",
    "TEST_TOPICS = 5\n",
    "TOP_K = 20\n",
    "RUN_TAG = \"llama31_8b_test\"\n",
    "\n",
    "CACHE_BASE = Path(r\"C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\matches_test\")\n",
    "OUT_DIR = Path(r\"C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\test_outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "full_run_path = OUT_DIR / f\"trialgpt_{RUN_TAG}_trec2021_{TEST_TOPICS}topics_top{TOP_K}.run\"\n",
    "table_path = OUT_DIR / f\"trialgpt_{RUN_TAG}_trec2021_{TEST_TOPICS}topics_top{TOP_K}_table.csv\"\n",
    "coverage_path = OUT_DIR / f\"trialgpt_{RUN_TAG}_trec2021_{TEST_TOPICS}topics_top{TOP_K}_coverage.csv\"\n",
    "\n",
    "def score_match(result_json: dict) -> float:\n",
    "    score = 0.0\n",
    "    inc = result_json.get(\"inclusion\", [])\n",
    "    exc = result_json.get(\"exclusion\", [])\n",
    "\n",
    "    for it in inc:\n",
    "        lab = (it.get(\"label\") or \"\").strip().lower()\n",
    "        if lab == \"met\":\n",
    "            score += 1.0\n",
    "        elif lab == \"not_met\":\n",
    "            score -= 1.0\n",
    "\n",
    "    for it in exc:\n",
    "        lab = (it.get(\"label\") or \"\").strip().lower()\n",
    "        if lab in {\"triggers\", \"met\"}:\n",
    "            score -= 4.0\n",
    "        elif lab in {\"does_not_trigger\", \"not_met\"}:\n",
    "            score += 0.5\n",
    "\n",
    "    return score\n",
    "\n",
    "topic_ids = sorted(queries_df[\"topic_id\"].astype(str).unique(), key=lambda x: int(x))[:TEST_TOPICS]\n",
    "\n",
    "all_lines = []\n",
    "rows = []\n",
    "cov_rows = []\n",
    "runname = f\"trialgpt_{RUN_TAG}\"\n",
    "\n",
    "for topic_id in topic_ids:\n",
    "    cands = (\n",
    "        run_df[run_df[\"topic_id\"].astype(str) == topic_id]\n",
    "        .sort_values(\"rank\")\n",
    "        .head(TOP_K)[[\"doc_id\", \"rank\", \"score\"]]\n",
    "        .rename(columns={\"doc_id\": \"trial_id\", \"rank\": \"bm25_rank\", \"score\": \"bm25_score\"})\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    topic_dir = CACHE_BASE / f\"topic_{topic_id}\"\n",
    "    matched = []\n",
    "\n",
    "    for r in cands.itertuples(index=False):\n",
    "        json_path = topic_dir / f\"{r.trial_id}_{RUN_TAG}.json\"\n",
    "        if not json_path.exists():\n",
    "            continue\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            mj = json.load(f)\n",
    "\n",
    "        agg = score_match(mj)\n",
    "        matched.append((r.trial_id, float(agg), float(r.bm25_score), int(r.bm25_rank), mj.get(\"overall_assessment\", \"\"), mj.get(\"notes\", \"\")))\n",
    "\n",
    "    cov_rows.append({\n",
    "        \"topic_id\": topic_id,\n",
    "        \"candidates\": len(cands),\n",
    "        \"matched_cached\": len(matched),\n",
    "        \"missing_cached\": len(cands) - len(matched)\n",
    "    })\n",
    "\n",
    "    if not matched:\n",
    "        continue\n",
    "\n",
    "    ranked = (\n",
    "        pd.DataFrame(matched, columns=[\"trial_id\", \"agg_score\", \"bm25_score\", \"bm25_rank\", \"overall_assessment\", \"notes\"])\n",
    "        .sort_values([\"agg_score\", \"bm25_score\"], ascending=[False, False])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # write run lines\n",
    "    for rank, rr in enumerate(ranked.itertuples(index=False), start=1):\n",
    "        all_lines.append(f\"{topic_id} Q0 {rr.trial_id} {rank} {rr.agg_score:.6f} {runname}\\n\")\n",
    "\n",
    "    # store table rows\n",
    "    for rr in ranked.itertuples(index=False):\n",
    "        rows.append({\n",
    "            \"topic_id\": topic_id,\n",
    "            \"trial_id\": rr.trial_id,\n",
    "            \"agg_score\": rr.agg_score,\n",
    "            \"bm25_score\": rr.bm25_score,\n",
    "            \"bm25_rank\": rr.bm25_rank,\n",
    "            \"overall_assessment\": rr.overall_assessment,\n",
    "            \"notes\": rr.notes\n",
    "        })\n",
    "\n",
    "# save outputs\n",
    "with open(full_run_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(all_lines)\n",
    "\n",
    "table_df = pd.DataFrame(rows)\n",
    "coverage_df = pd.DataFrame(cov_rows)\n",
    "\n",
    "table_df.to_csv(table_path, index=False)\n",
    "coverage_df.to_csv(coverage_path, index=False)\n",
    "\n",
    "print(\"✅ Saved reranked TEST run to:\")\n",
    "print(full_run_path)\n",
    "print(\"\\n✅ Saved table to:\")\n",
    "print(table_path)\n",
    "print(\"\\n✅ Saved coverage to:\")\n",
    "print(coverage_path)\n",
    "\n",
    "print(\"\\nCoverage:\")\n",
    "display(coverage_df)\n",
    "\n",
    "print(\"\\nSample reranked rows:\")\n",
    "display(table_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12814ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>P@10</th>\n",
       "      <th>R@10</th>\n",
       "      <th>R@20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.0510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TrialGPT-test</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.0381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  P@10    R@10    R@20\n",
       "0           BM25  0.54  0.0312  0.0510\n",
       "1  TrialGPT-test  0.52  0.0282  0.0381"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---------- paths ----------\n",
    "BM25_RUN = Path(r\"C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\bm25_python_trec2021_top100.run\")\n",
    "TRIALGPT_RUN = Path(r\"C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\test_outputs\\trialgpt_llama31_8b_test_trec2021_5topics_top20.run\")\n",
    "\n",
    "TEST_TOPICS = set([\"1\", \"2\", \"3\", \"4\", \"5\"])\n",
    "\n",
    "# ---------- load run files ----------\n",
    "def load_run(path):\n",
    "    rows = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            topic, _, docid, rank, score, runname = line.strip().split()\n",
    "            if topic in TEST_TOPICS:\n",
    "                rows.append({\n",
    "                    \"topic_id\": topic,\n",
    "                    \"doc_id\": docid,\n",
    "                    \"rank\": int(rank)\n",
    "                })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "bm25_df = load_run(BM25_RUN)\n",
    "trialgpt_df = load_run(TRIALGPT_RUN)\n",
    "\n",
    "# ---------- metric function ----------\n",
    "def precision_recall_at_k(run_df, qrels_df, k):\n",
    "    rel = (\n",
    "        qrels_df[qrels_df[\"relevance\"] > 0]\n",
    "        .groupby(\"topic_id\")[\"doc_id\"]\n",
    "        .apply(set)\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    precisions, recalls = [], []\n",
    "\n",
    "    for topic in TEST_TOPICS:\n",
    "        retrieved = (\n",
    "            run_df[run_df[\"topic_id\"] == topic]\n",
    "            .sort_values(\"rank\")\n",
    "            .head(k)[\"doc_id\"]\n",
    "            .tolist()\n",
    "        )\n",
    "        relevant = rel.get(topic, set())\n",
    "\n",
    "        if not relevant:\n",
    "            continue\n",
    "\n",
    "        hits = sum(1 for d in retrieved if d in relevant)\n",
    "        precisions.append(hits / k)\n",
    "        recalls.append(hits / len(relevant))\n",
    "\n",
    "    return sum(precisions)/len(precisions), sum(recalls)/len(recalls)\n",
    "\n",
    "# ---------- compute ----------\n",
    "metrics = []\n",
    "\n",
    "for name, df in [(\"BM25\", bm25_df), (\"TrialGPT-test\", trialgpt_df)]:\n",
    "    p10, r10 = precision_recall_at_k(df, qrels_df, 10)\n",
    "    p20, r20 = precision_recall_at_k(df, qrels_df, 20)\n",
    "    metrics.append({\n",
    "        \"model\": name,\n",
    "        \"P@10\": round(p10, 4),\n",
    "        \"R@10\": round(r10, 4),\n",
    "        \"R@20\": round(r20, 4)\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ed0af18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):   1%|▏         | 1/75 [15:23<18:58:32, 923.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 1] saved=53 skipped=38 errors=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):   3%|▎         | 2/75 [34:27<21:21:26, 1053.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 2] saved=97 skipped=0 errors=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):   4%|▍         | 3/75 [53:44<22:01:00, 1100.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 3] saved=97 skipped=0 errors=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):   5%|▌         | 4/75 [1:15:25<23:16:08, 1179.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 4] saved=90 skipped=0 errors=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):   7%|▋         | 5/75 [1:33:56<22:27:19, 1154.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 5] saved=99 skipped=0 errors=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):   8%|▊         | 6/75 [1:53:57<22:26:06, 1170.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 6] saved=92 skipped=0 errors=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):   9%|▉         | 7/75 [2:13:21<22:04:11, 1168.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 7] saved=98 skipped=0 errors=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  11%|█         | 8/75 [2:30:44<21:00:02, 1128.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 8] saved=100 skipped=0 errors=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  12%|█▏        | 9/75 [2:51:16<21:17:03, 1160.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 9] saved=98 skipped=0 errors=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  13%|█▎        | 10/75 [3:13:07<21:47:52, 1207.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 10] saved=97 skipped=0 errors=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  15%|█▍        | 11/75 [3:32:32<21:13:47, 1194.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 11] saved=96 skipped=0 errors=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  16%|█▌        | 12/75 [3:53:13<21:08:50, 1208.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 12] saved=98 skipped=0 errors=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  17%|█▋        | 13/75 [4:13:12<20:45:47, 1205.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 13] saved=97 skipped=0 errors=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  19%|█▊        | 14/75 [4:33:03<20:21:09, 1201.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 14] saved=98 skipped=0 errors=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  20%|██        | 15/75 [4:51:44<19:37:07, 1177.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 15] saved=98 skipped=0 errors=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  21%|██▏       | 16/75 [5:12:47<19:42:55, 1202.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 16] saved=98 skipped=0 errors=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  23%|██▎       | 17/75 [5:36:44<20:30:54, 1273.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 17] saved=92 skipped=0 errors=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  24%|██▍       | 18/75 [5:55:41<19:30:49, 1232.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 18] saved=98 skipped=0 errors=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  25%|██▌       | 19/75 [6:13:55<18:31:24, 1190.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 19] saved=100 skipped=0 errors=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  27%|██▋       | 20/75 [6:33:56<18:14:16, 1193.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 20] saved=96 skipped=0 errors=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  28%|██▊       | 21/75 [6:52:45<17:36:57, 1174.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 21] saved=99 skipped=0 errors=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  29%|██▉       | 22/75 [7:10:22<16:46:10, 1139.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 22] saved=99 skipped=0 errors=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  31%|███       | 23/75 [7:32:29<17:16:09, 1195.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 23] saved=93 skipped=0 errors=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  32%|███▏      | 24/75 [7:53:54<17:19:02, 1222.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 24] saved=94 skipped=0 errors=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  33%|███▎      | 25/75 [8:15:50<17:22:01, 1250.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 25] saved=98 skipped=0 errors=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  35%|███▍      | 26/75 [8:34:23<16:27:28, 1209.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 26] saved=97 skipped=0 errors=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  36%|███▌      | 27/75 [8:56:42<16:38:35, 1248.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 27] saved=92 skipped=0 errors=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  37%|███▋      | 28/75 [9:15:19<15:46:51, 1208.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 28] saved=99 skipped=0 errors=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  39%|███▊      | 29/75 [9:34:21<15:11:28, 1188.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 29] saved=95 skipped=0 errors=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  40%|████      | 30/75 [9:53:10<14:38:11, 1170.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 30] saved=97 skipped=0 errors=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  41%|████▏     | 31/75 [10:11:33<14:03:40, 1150.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 31] saved=99 skipped=0 errors=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  43%|████▎     | 32/75 [10:32:15<14:04:04, 1177.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 32] saved=94 skipped=0 errors=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  44%|████▍     | 33/75 [10:53:00<13:58:42, 1198.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 33] saved=96 skipped=0 errors=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  45%|████▌     | 34/75 [11:12:16<13:29:59, 1185.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 34] saved=99 skipped=0 errors=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  47%|████▋     | 35/75 [11:31:27<13:03:18, 1174.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 35] saved=97 skipped=0 errors=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  48%|████▊     | 36/75 [11:52:48<13:04:27, 1206.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 36] saved=94 skipped=0 errors=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  49%|████▉     | 37/75 [12:13:16<12:48:28, 1213.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 37] saved=95 skipped=0 errors=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  51%|█████     | 38/75 [12:34:10<12:35:42, 1225.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 38] saved=95 skipped=0 errors=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  52%|█████▏    | 39/75 [12:52:49<11:56:11, 1193.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 39] saved=94 skipped=0 errors=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  53%|█████▎    | 40/75 [13:11:14<11:20:41, 1166.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 40] saved=97 skipped=0 errors=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  55%|█████▍    | 41/75 [13:29:26<10:48:29, 1144.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 41] saved=100 skipped=0 errors=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  56%|█████▌    | 42/75 [13:49:58<10:43:51, 1170.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 42] saved=96 skipped=0 errors=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  57%|█████▋    | 43/75 [14:10:13<10:31:27, 1183.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 43] saved=95 skipped=0 errors=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  59%|█████▊    | 44/75 [14:28:15<9:55:52, 1153.30s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 44] saved=97 skipped=0 errors=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  60%|██████    | 45/75 [14:49:37<9:55:59, 1191.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 45] saved=95 skipped=0 errors=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  61%|██████▏   | 46/75 [15:11:59<9:57:57, 1237.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 46] saved=90 skipped=0 errors=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  63%|██████▎   | 47/75 [15:31:24<9:27:13, 1215.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 47] saved=99 skipped=0 errors=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  64%|██████▍   | 48/75 [15:49:58<8:53:16, 1185.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 48] saved=99 skipped=0 errors=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  65%|██████▌   | 49/75 [16:08:54<8:27:09, 1170.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 49] saved=97 skipped=0 errors=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  67%|██████▋   | 50/75 [16:26:57<7:56:41, 1144.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 50] saved=96 skipped=0 errors=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  68%|██████▊   | 51/75 [16:47:37<7:49:07, 1172.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 51] saved=96 skipped=0 errors=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  69%|██████▉   | 52/75 [17:07:40<7:33:02, 1181.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 52] saved=100 skipped=0 errors=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  71%|███████   | 53/75 [17:28:25<7:20:16, 1200.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 53] saved=94 skipped=0 errors=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  72%|███████▏  | 54/75 [17:49:26<7:06:37, 1218.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 54] saved=95 skipped=0 errors=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  73%|███████▎  | 55/75 [18:07:15<6:31:18, 1173.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 55] saved=99 skipped=0 errors=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  75%|███████▍  | 56/75 [18:25:22<6:03:27, 1147.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 56] saved=100 skipped=0 errors=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  76%|███████▌  | 57/75 [18:44:05<5:42:09, 1140.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 57] saved=98 skipped=0 errors=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  77%|███████▋  | 58/75 [19:00:33<5:10:09, 1094.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 58] saved=98 skipped=0 errors=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  79%|███████▊  | 59/75 [19:19:42<4:56:17, 1111.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 59] saved=99 skipped=0 errors=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  80%|████████  | 60/75 [19:41:59<4:54:39, 1178.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 60] saved=91 skipped=0 errors=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  81%|████████▏ | 61/75 [20:05:48<4:52:32, 1253.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 61] saved=95 skipped=0 errors=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  83%|████████▎ | 62/75 [20:23:35<4:19:30, 1197.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 62] saved=99 skipped=0 errors=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  84%|████████▍ | 63/75 [20:42:07<3:54:24, 1172.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 63] saved=95 skipped=0 errors=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  85%|████████▌ | 64/75 [21:04:21<3:43:48, 1220.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 64] saved=90 skipped=0 errors=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  87%|████████▋ | 65/75 [21:25:14<3:25:04, 1230.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 65] saved=98 skipped=0 errors=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  88%|████████▊ | 66/75 [21:44:53<3:02:14, 1214.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 66] saved=98 skipped=0 errors=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  89%|████████▉ | 67/75 [22:03:38<2:38:23, 1187.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 67] saved=97 skipped=0 errors=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  91%|█████████ | 68/75 [22:22:59<2:17:39, 1179.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 68] saved=96 skipped=0 errors=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  92%|█████████▏| 69/75 [22:44:20<2:01:00, 1210.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 69] saved=98 skipped=0 errors=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  93%|█████████▎| 70/75 [23:04:28<1:40:47, 1209.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 70] saved=98 skipped=0 errors=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  95%|█████████▍| 71/75 [23:24:03<1:19:57, 1199.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 71] saved=97 skipped=0 errors=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  96%|█████████▌| 72/75 [23:44:30<1:00:22, 1207.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 72] saved=98 skipped=0 errors=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  97%|█████████▋| 73/75 [24:04:07<39:56, 1198.27s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 73] saved=92 skipped=0 errors=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75):  99%|█████████▊| 74/75 [24:22:56<19:37, 1177.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 74] saved=98 skipped=0 errors=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FULL topics (75): 100%|██████████| 75/75 [24:41:17<00:00, 1185.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Topic 75] saved=99 skipped=0 errors=1\n",
      "\n",
      " FULL MATCHING DONE (or resumed)\n",
      "Total saved: 7197\n",
      "Total skipped: 38\n",
      "Total errors: 265\n",
      "Cache base: C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\matches_full_top100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------ FULL RUN SETTINGS ------------------\n",
    "TOP_K = 100\n",
    "RUN_TAG = \"llama31_8b_full_top100\"\n",
    "SLEEP_SEC = 0.0                 # set 0.1–0.3 if Ollama gets unstable\n",
    "NUM_PREDICT = 900               # higher cap reduces truncated JSON\n",
    "INCL_SLICE = 45                 # criteria slices (balance speed vs accuracy)\n",
    "EXCL_SLICE = 35\n",
    "\n",
    "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "OLLAMA_MODEL = \"llama3.1:8b\"\n",
    "\n",
    "CACHE_BASE = Path(r\"C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\matches_full_top100\")\n",
    "CACHE_BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def cache_path(topic_id: str, trial_id: str) -> Path:\n",
    "    topic_dir = CACHE_BASE / f\"topic_{topic_id}\"\n",
    "    topic_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return topic_dir / f\"{trial_id}_{RUN_TAG}.json\"\n",
    "\n",
    "def error_path(topic_id: str, trial_id: str) -> Path:\n",
    "    topic_dir = CACHE_BASE / f\"topic_{topic_id}\"\n",
    "    topic_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return topic_dir / f\"{trial_id}_{RUN_TAG}.error.txt\"\n",
    "\n",
    "def ollama_generate(prompt: str, temperature: float = 0.0, num_predict: int = NUM_PREDICT) -> str:\n",
    "    payload = {\n",
    "        \"model\": OLLAMA_MODEL,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": temperature,\n",
    "            \"num_predict\": num_predict,\n",
    "        }\n",
    "    }\n",
    "    r = requests.post(OLLAMA_URL, json=payload, timeout=300)\n",
    "    r.raise_for_status()\n",
    "    return r.json()[\"response\"]\n",
    "\n",
    "def build_matching_prompt(patient_text: str, inclusion: list, exclusion: list, trial_id: str) -> str:\n",
    "    inc = \"\\n\".join([f\"- {c}\" for c in inclusion[:INCL_SLICE]])\n",
    "    exc = \"\\n\".join([f\"- {c}\" for c in exclusion[:EXCL_SLICE]])\n",
    "\n",
    "    return f\"\"\"\n",
    "Return ONLY valid JSON (no markdown, no extra text).\n",
    "\n",
    "Schema:\n",
    "{{\n",
    "  \"trial_id\": \"{trial_id}\",\n",
    "  \"overall_assessment\": \"likely_eligible\" | \"likely_ineligible\" | \"uncertain\",\n",
    "  \"inclusion\": [{{\"criterion\":\"...\",\"label\":\"met|not_met|unknown\",\"evidence\":\"quote|none\"}}],\n",
    "  \"exclusion\":  [{{\"criterion\":\"...\",\"label\":\"triggers|does_not_trigger|unknown\",\"evidence\":\"quote|none\"}}],\n",
    "  \"notes\": \"1-2 sentences\"\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- Use ONLY patient text. If not stated, label unknown.\n",
    "- Pick at most 12 inclusion and 8 exclusion items (most decisive).\n",
    "- Be conservative: if any exclusion likely triggers, overall_assessment should be likely_ineligible.\n",
    "\n",
    "PATIENT:\n",
    "{patient_text}\n",
    "\n",
    "INCLUSION (subset):\n",
    "{inc if inc.strip() else \"- (none found)\"}\n",
    "\n",
    "EXCLUSION (subset):\n",
    "{exc if exc.strip() else \"- (none found)\"}\n",
    "\"\"\".strip()\n",
    "\n",
    "def safe_json_load(s: str):\n",
    "    s = s.strip()\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except Exception:\n",
    "        pass\n",
    "    start = s.find(\"{\")\n",
    "    end = s.rfind(\"}\")\n",
    "    if start != -1 and end != -1 and end > start:\n",
    "        return json.loads(s[start:end+1])\n",
    "    raise ValueError(\"Could not parse JSON from model output.\")\n",
    "\n",
    "# ------------------ FULL RUN LOOP ------------------\n",
    "topic_ids = sorted(queries_df[\"topic_id\"].astype(str).unique(), key=lambda x: int(x))\n",
    "\n",
    "total_saved = total_skipped = total_errors = 0\n",
    "\n",
    "for topic_id in tqdm(topic_ids, desc=\"FULL topics (75)\"):\n",
    "    patient_text = queries_df.loc[queries_df[\"topic_id\"].astype(str) == topic_id, \"text\"].iloc[0]\n",
    "\n",
    "    cands = (\n",
    "        run_df[run_df[\"topic_id\"].astype(str) == topic_id]\n",
    "        .sort_values(\"rank\")\n",
    "        .head(TOP_K)[\"doc_id\"]\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "    saved = skipped = errors = 0\n",
    "\n",
    "    for trial_id in tqdm(cands, desc=f\"Topic {topic_id}\", leave=False):\n",
    "        out_json = cache_path(topic_id, trial_id)\n",
    "        if out_json.exists():\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            trial_text = get_trial_text(trial_id)\n",
    "            elig = extract_eligibility(trial_text)\n",
    "\n",
    "            prompt = build_matching_prompt(patient_text, elig[\"inclusion\"], elig[\"exclusion\"], trial_id)\n",
    "            raw = ollama_generate(prompt, temperature=0.0, num_predict=NUM_PREDICT)\n",
    "            match_json = safe_json_load(raw)\n",
    "\n",
    "            match_json[\"_meta\"] = {\n",
    "                \"topic_id\": topic_id,\n",
    "                \"trial_id\": trial_id,\n",
    "                \"model\": OLLAMA_MODEL,\n",
    "                \"run_tag\": RUN_TAG,\n",
    "                \"top_k\": TOP_K\n",
    "            }\n",
    "\n",
    "            with open(out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(match_json, f, indent=2)\n",
    "\n",
    "            saved += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            errors += 1\n",
    "            with open(error_path(topic_id, trial_id), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(str(e))\n",
    "\n",
    "        if SLEEP_SEC > 0:\n",
    "            time.sleep(SLEEP_SEC)\n",
    "\n",
    "    total_saved += saved\n",
    "    total_skipped += skipped\n",
    "    total_errors += errors\n",
    "\n",
    "    print(f\"\\n[Topic {topic_id}] saved={saved} skipped={skipped} errors={errors}\")\n",
    "\n",
    "print(\"\\n FULL MATCHING DONE (or resumed)\")\n",
    "print(\"Total saved:\", total_saved)\n",
    "print(\"Total skipped:\", total_skipped)\n",
    "print(\"Total errors:\", total_errors)\n",
    "print(\"Cache base:\", str(CACHE_BASE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "285c835f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved FULL reranked run: C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\full_outputs\\trialgpt_llama31_8b_full_top100_trec2021_top100.run\n",
      "✅ Saved coverage report: C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\full_outputs\\trialgpt_llama31_8b_full_top100_trec2021_top100_coverage.csv\n",
      "✅ Saved rerank table: C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\full_outputs\\trialgpt_llama31_8b_full_top100_trec2021_top100_table.csv\n",
      "\n",
      "Coverage summary:\n",
      "count     75.000000\n",
      "mean      96.466667\n",
      "std        2.616648\n",
      "min       90.000000\n",
      "25%       95.000000\n",
      "50%       97.000000\n",
      "75%       98.000000\n",
      "max      100.000000\n",
      "Name: matched_cached, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>candidates</th>\n",
       "      <th>matched_cached</th>\n",
       "      <th>missing_cached</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>91</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>97</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>97</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>92</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>97</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  topic_id  candidates  matched_cached  missing_cached\n",
       "0        1         100              91               9\n",
       "1        2         100              97               3\n",
       "2        3         100              97               3\n",
       "3        4         100              90              10\n",
       "4        5         100              99               1\n",
       "5        6         100              92               8\n",
       "6        7         100              98               2\n",
       "7        8         100             100               0\n",
       "8        9         100              98               2\n",
       "9       10         100              97               3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "TOP_K = 100\n",
    "RUN_TAG = \"llama31_8b_full_top100\"\n",
    "OLLAMA_MODEL = \"llama3.1:8b\"\n",
    "\n",
    "CACHE_BASE = Path(r\"C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\matches_full_top100\")\n",
    "OUT_DIR = Path(r\"C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\full_outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "full_run_path = OUT_DIR / f\"trialgpt_{RUN_TAG}_trec2021_top{TOP_K}.run\"\n",
    "coverage_path = OUT_DIR / f\"trialgpt_{RUN_TAG}_trec2021_top{TOP_K}_coverage.csv\"\n",
    "table_path = OUT_DIR / f\"trialgpt_{RUN_TAG}_trec2021_top{TOP_K}_table.csv\"\n",
    "\n",
    "def score_match(result_json: dict) -> float:\n",
    "    # deterministic aggregator (same idea as before)\n",
    "    score = 0.0\n",
    "    inc = result_json.get(\"inclusion\", [])\n",
    "    exc = result_json.get(\"exclusion\", [])\n",
    "\n",
    "    for it in inc:\n",
    "        lab = (it.get(\"label\") or \"\").strip().lower()\n",
    "        if lab == \"met\":\n",
    "            score += 1.0\n",
    "        elif lab == \"not_met\":\n",
    "            score -= 1.0\n",
    "\n",
    "    for it in exc:\n",
    "        lab = (it.get(\"label\") or \"\").strip().lower()\n",
    "        if lab in {\"triggers\", \"met\"}:\n",
    "            score -= 4.0\n",
    "        elif lab in {\"does_not_trigger\", \"not_met\"}:\n",
    "            score += 0.5\n",
    "\n",
    "    return score\n",
    "\n",
    "topic_ids = sorted(queries_df[\"topic_id\"].astype(str).unique(), key=lambda x: int(x))\n",
    "\n",
    "all_lines = []\n",
    "table_rows = []\n",
    "cov_rows = []\n",
    "\n",
    "runname = f\"trialgpt_{RUN_TAG}\"\n",
    "\n",
    "for topic_id in topic_ids:\n",
    "    cands = (\n",
    "        run_df[run_df[\"topic_id\"].astype(str) == topic_id]\n",
    "        .sort_values(\"rank\")\n",
    "        .head(TOP_K)[[\"doc_id\", \"rank\", \"score\"]]\n",
    "        .rename(columns={\"doc_id\": \"trial_id\", \"rank\": \"bm25_rank\", \"score\": \"bm25_score\"})\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    topic_dir = CACHE_BASE / f\"topic_{topic_id}\"\n",
    "    matched = []\n",
    "    missing = 0\n",
    "\n",
    "    for r in cands.itertuples(index=False):\n",
    "        json_path = topic_dir / f\"{r.trial_id}_{RUN_TAG}.json\"\n",
    "        if not json_path.exists():\n",
    "            missing += 1\n",
    "            continue\n",
    "\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            mj = json.load(f)\n",
    "\n",
    "        agg = score_match(mj)\n",
    "        matched.append({\n",
    "            \"trial_id\": r.trial_id,\n",
    "            \"agg_score\": float(agg),\n",
    "            \"bm25_score\": float(r.bm25_score),\n",
    "            \"bm25_rank\": int(r.bm25_rank),\n",
    "            \"overall_assessment\": mj.get(\"overall_assessment\", \"\"),\n",
    "            \"notes\": mj.get(\"notes\", \"\")\n",
    "        })\n",
    "\n",
    "    cov_rows.append({\n",
    "        \"topic_id\": topic_id,\n",
    "        \"candidates\": len(cands),\n",
    "        \"matched_cached\": len(matched),\n",
    "        \"missing_cached\": missing\n",
    "    })\n",
    "\n",
    "    if not matched:\n",
    "        continue\n",
    "\n",
    "    ranked = (\n",
    "        pd.DataFrame(matched)\n",
    "        .sort_values([\"agg_score\", \"bm25_score\"], ascending=[False, False])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # write TREC run lines for this topic\n",
    "    for rank, row in enumerate(ranked.itertuples(index=False), start=1):\n",
    "        all_lines.append(f\"{topic_id} Q0 {row.trial_id} {rank} {row.agg_score:.6f} {runname}\\n\")\n",
    "\n",
    "    # store table rows\n",
    "    for row in ranked.itertuples(index=False):\n",
    "        table_rows.append({\n",
    "            \"topic_id\": topic_id,\n",
    "            \"trial_id\": row.trial_id,\n",
    "            \"agg_score\": row.agg_score,\n",
    "            \"bm25_score\": row.bm25_score,\n",
    "            \"bm25_rank\": row.bm25_rank,\n",
    "            \"overall_assessment\": row.overall_assessment,\n",
    "            \"notes\": row.notes\n",
    "        })\n",
    "\n",
    "with open(full_run_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(all_lines)\n",
    "\n",
    "coverage_df = pd.DataFrame(cov_rows)\n",
    "table_df = pd.DataFrame(table_rows)\n",
    "\n",
    "coverage_df.to_csv(coverage_path, index=False)\n",
    "table_df.to_csv(table_path, index=False)\n",
    "\n",
    "print(\"✅ Saved FULL reranked run:\", full_run_path)\n",
    "print(\"✅ Saved coverage report:\", coverage_path)\n",
    "print(\"✅ Saved rerank table:\", table_path)\n",
    "\n",
    "print(\"\\nCoverage summary:\")\n",
    "print(coverage_df[\"matched_cached\"].describe())\n",
    "display(coverage_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e083e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved metrics: C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\full_outputs\\trialgpt_llama31_8b_full_top100_trec2021_metrics.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Precision@100</th>\n",
       "      <th>Recall@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.027917</td>\n",
       "      <td>0.148533</td>\n",
       "      <td>0.104029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TrialGPT-local (llama31_8b_full_top100)</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.012462</td>\n",
       "      <td>0.144533</td>\n",
       "      <td>0.101909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     model  Precision@10  Recall@10  \\\n",
       "0                                     BM25      0.300000   0.027917   \n",
       "1  TrialGPT-local (llama31_8b_full_top100)      0.173333   0.012462   \n",
       "\n",
       "   Precision@100  Recall@100  \n",
       "0       0.148533    0.104029  \n",
       "1       0.144533    0.101909  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "TOP_K = 100\n",
    "RUN_TAG = \"llama31_8b_full_top100\"\n",
    "\n",
    "BM25_RUN_PATH = Path(r\"C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\bm25_python_trec2021_top100.run\")\n",
    "TRIALGPT_RUN_PATH = Path(r\"C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\full_outputs\") / f\"trialgpt_{RUN_TAG}_trec2021_top{TOP_K}.run\"\n",
    "OUT_METRICS_PATH = Path(r\"C:\\Ajesh_Drive\\PersonalProjects\\ClinicalTrialNexus\\models\\user\\trialgpt_local\\full_outputs\") / f\"trialgpt_{RUN_TAG}_trec2021_metrics.csv\"\n",
    "\n",
    "def load_run(path: Path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 6:\n",
    "                continue\n",
    "            topic, _, docid, rank, score, runname = parts[:6]\n",
    "            rows.append({\"topic_id\": str(topic), \"doc_id\": docid, \"rank\": int(rank)})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def precision_recall_at_k(run_df: pd.DataFrame, qrels_df: pd.DataFrame, k: int):\n",
    "    rel = (\n",
    "        qrels_df[qrels_df[\"relevance\"] > 0]\n",
    "        .groupby(\"topic_id\")[\"doc_id\"]\n",
    "        .apply(set)\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    topics = sorted(set(run_df[\"topic_id\"]) & set(qrels_df[\"topic_id\"].astype(str)))\n",
    "    precisions, recalls = [], []\n",
    "\n",
    "    for t in topics:\n",
    "        retrieved = (\n",
    "            run_df[run_df[\"topic_id\"] == t]\n",
    "            .sort_values(\"rank\")\n",
    "            .head(k)[\"doc_id\"]\n",
    "            .tolist()\n",
    "        )\n",
    "        relevant = rel.get(t, set())\n",
    "        if not relevant:\n",
    "            continue\n",
    "\n",
    "        hits = sum(1 for d in retrieved if d in relevant)\n",
    "        precisions.append(hits / k)\n",
    "        recalls.append(hits / len(relevant))\n",
    "\n",
    "    return float(sum(precisions) / len(precisions)), float(sum(recalls) / len(recalls))\n",
    "\n",
    "bm25_df = load_run(BM25_RUN_PATH)\n",
    "trialgpt_df = load_run(TRIALGPT_RUN_PATH)\n",
    "\n",
    "p10_b, r10_b = precision_recall_at_k(bm25_df, qrels_df, 10)\n",
    "p100_b, r100_b = precision_recall_at_k(bm25_df, qrels_df, 100)\n",
    "\n",
    "p10_t, r10_t = precision_recall_at_k(trialgpt_df, qrels_df, 10)\n",
    "p100_t, r100_t = precision_recall_at_k(trialgpt_df, qrels_df, 100)\n",
    "\n",
    "metrics_df = pd.DataFrame([\n",
    "    {\"model\": \"BM25\", \"Precision@10\": p10_b, \"Recall@10\": r10_b, \"Precision@100\": p100_b, \"Recall@100\": r100_b},\n",
    "    {\"model\": f\"TrialGPT-local ({RUN_TAG})\", \"Precision@10\": p10_t, \"Recall@10\": r10_t, \"Precision@100\": p100_t, \"Recall@100\": r100_t},\n",
    "])\n",
    "\n",
    "metrics_df.to_csv(OUT_METRICS_PATH, index=False)\n",
    "\n",
    "print(\"✅ Saved metrics:\", OUT_METRICS_PATH)\n",
    "display(metrics_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
